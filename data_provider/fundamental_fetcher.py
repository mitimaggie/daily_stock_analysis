# -*- coding: utf-8 -*-
"""
===================================
åŸºæœ¬é¢æ•°æ®è·å–å™¨ (F10)
===================================
èŒè´£ï¼šè·å–ä¸ªè‚¡çš„è´¢åŠ¡æ‘˜è¦ã€ä¼°å€¼æŒ‡æ ‡ã€ä¸šç»©é¢„æµ‹
æ•°æ®æºä¼˜å…ˆçº§ï¼šåŒèŠ±é¡º(THS) -> ä¸œæ–¹è´¢å¯Œ(EM) -> é™çº§(ä»…PE/PB)
ç¼“å­˜ç­–ç•¥ï¼šL1 è¿›ç¨‹å†…å­˜ + L2 SQLite æŒä¹…åŒ–
  - F10 è´¢åŠ¡æ•°æ®: TTL=7å¤©ï¼ˆå­£æŠ¥çº§ï¼Œå‡ ä¹ä¸å˜ï¼‰
  - è¡Œä¸š PE ä¸­ä½æ•°: TTL=24å°æ—¶
é£æ§ï¼šä¸¥æ ¼é™åˆ¶è¯·æ±‚é¢‘ç‡ï¼Œå…¨å±€è®¡æ•°å™¨é˜²æ­¢ IP è¢«å°
"""
import logging
import time
import random
import threading
from typing import Dict, Optional, Any

logger = logging.getLogger(__name__)

# === å…¨å±€è¯·æ±‚é™æµå™¨ï¼ˆæ‰€æœ‰ akshare è°ƒç”¨å…±äº«ï¼‰ ===
_request_lock = threading.Lock()
_request_timestamps: list = []  # è®°å½•æœ€è¿‘è¯·æ±‚æ—¶é—´æˆ³
_MAX_REQUESTS_PER_MINUTE = 12   # æ¯åˆ†é’Ÿæœ€å¤š 12 æ¬¡è¯·æ±‚ï¼ˆä¿å®ˆï¼‰
_MIN_INTERVAL = 3.0             # æœ€å°è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰

def _rate_limited_sleep():
    """å…¨å±€é™æµï¼šç¡®ä¿ä¸è¶…è¿‡æ¯åˆ†é’Ÿ N æ¬¡è¯·æ±‚ï¼Œæ¯æ¬¡è‡³å°‘é—´éš” M ç§’"""
    with _request_lock:
        now = time.time()
        # æ¸…ç† 60s å‰çš„æ—¶é—´æˆ³
        _request_timestamps[:] = [t for t in _request_timestamps if now - t < 60]
        # è¶…è¿‡æ¯åˆ†é’Ÿä¸Šé™ï¼Œç­‰åˆ°æœ€æ—©çš„è¿‡æœŸ
        if len(_request_timestamps) >= _MAX_REQUESTS_PER_MINUTE:
            wait = 60 - (now - _request_timestamps[0]) + 1
            if wait > 0:
                logger.info(f"ğŸ›¡ï¸ é™æµç­‰å¾… {wait:.1f}sï¼ˆæ¯åˆ†é’Ÿä¸Šé™ {_MAX_REQUESTS_PER_MINUTE} æ¬¡ï¼‰")
                time.sleep(wait)
        # ç¡®ä¿ä¸ä¸Šæ¬¡è¯·æ±‚é—´éš”è¶³å¤Ÿ
        if _request_timestamps:
            elapsed = time.time() - _request_timestamps[-1]
            if elapsed < _MIN_INTERVAL:
                time.sleep(_MIN_INTERVAL - elapsed + random.uniform(0.5, 1.5))
        _request_timestamps.append(time.time())


# L1: è¿›ç¨‹å†…å­˜ç¼“å­˜
_fundamental_cache: Dict[str, Dict] = {}
_industry_pe_cache: Dict[str, float] = {}

# L2: SQLite ç¼“å­˜ TTL
_F10_CACHE_TTL_HOURS = 168.0     # 7å¤©
_INDUSTRY_PE_TTL_HOURS = 24.0    # 24å°æ—¶

def _get_db():
    """å»¶è¿Ÿè·å– DatabaseManagerï¼Œé¿å…å¾ªç¯å¯¼å…¥"""
    try:
        from src.storage import DatabaseManager
        return DatabaseManager()
    except Exception:
        return None


class FundamentalFetcher:
    def __init__(self):
        pass

    def get_f10_data(self, code: str) -> Dict[str, Any]:
        """è·å–æ•´åˆåçš„ F10 æ•°æ®ï¼ˆL1å†…å­˜ -> L2 DB -> ç½‘ç»œï¼‰"""
        # L1: è¿›ç¨‹å†…å­˜
        if code in _fundamental_cache:
            return _fundamental_cache[code]

        # L2: SQLite æŒä¹…åŒ–ç¼“å­˜
        db = _get_db()
        if db:
            cached = db.get_cache('f10', code, ttl_hours=_F10_CACHE_TTL_HOURS)
            if cached:
                _fundamental_cache[code] = cached  # å›å¡« L1
                logger.info(f"ğŸ’¾ [{code}] F10 å‘½ä¸­ DB ç¼“å­˜ï¼ˆè·³è¿‡ç½‘ç»œè¯·æ±‚ï¼‰")
                return cached

        # L3: ç½‘ç»œè¯·æ±‚
        data = self._fetch_from_network(code)

        # å›å†™ç¼“å­˜
        if data.get('financial'):
            _fundamental_cache[code] = data
            if db:
                db.set_cache('f10', code, data)

        return data

    def _fetch_from_network(self, code: str) -> Dict[str, Any]:
        """ä»ç½‘ç»œè·å– F10 æ•°æ®ï¼ˆTHS -> EM fallbackï¼‰"""
        data = {"valuation": {}, "financial": {}, "forecast": {}}

        try:
            import akshare as ak

            # === A. è´¢åŠ¡æ‘˜è¦ï¼šä¼˜å…ˆåŒèŠ±é¡ºï¼Œå¤±è´¥å›é€€ä¸œè´¢ ===
            financial_ok = False

            # A1. åŒèŠ±é¡º
            _rate_limited_sleep()
            try:
                df_fin = ak.stock_financial_abstract_ths(symbol=code)
                if df_fin is not None and not df_fin.empty:
                    latest = df_fin.iloc[-1]
                    data["financial"] = {
                        "date": str(latest.get("æŠ¥å‘ŠæœŸ", "")),
                        "roe": str(latest.get("å‡€èµ„äº§æ”¶ç›Šç‡", "N/A")),
                        "net_profit_growth": str(latest.get("å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿ç‡", "N/A")),
                        "revenue_growth": str(latest.get("è¥ä¸šæ€»æ”¶å…¥åŒæ¯”å¢é•¿ç‡", "N/A")),
                        "gross_margin": str(latest.get("é”€å”®æ¯›åˆ©ç‡", "N/A")),
                        "debt_ratio": str(latest.get("èµ„äº§è´Ÿå€ºç‡", "N/A")),
                        "source": "ths"
                    }
                    financial_ok = True
            except Exception as e:
                logger.warning(f"[{code}] THS è´¢åŠ¡æ•°æ®å¤±è´¥: {e}")

            # A2. ä¸œè´¢ fallback
            if not financial_ok:
                _rate_limited_sleep()
                try:
                    df_em = ak.stock_financial_analysis_indicator_em(symbol=code, indicator="æŒ‰æŠ¥å‘ŠæœŸ")
                    if df_em is not None and not df_em.empty:
                        latest = df_em.iloc[0]
                        data["financial"] = {
                            "date": str(latest.get("æŠ¥å‘ŠæœŸ", "")),
                            "roe": str(latest.get("å‡€èµ„äº§æ”¶ç›Šç‡", latest.get("åŠ æƒå‡€èµ„äº§æ”¶ç›Šç‡", "N/A"))),
                            "net_profit_growth": str(latest.get("å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿ç‡", "N/A")),
                            "revenue_growth": str(latest.get("è¥ä¸šæ€»æ”¶å…¥åŒæ¯”å¢é•¿ç‡", latest.get("è¥ä¸šæ”¶å…¥åŒæ¯”å¢é•¿ç‡", "N/A"))),
                            "gross_margin": str(latest.get("é”€å”®æ¯›åˆ©ç‡", "N/A")),
                            "debt_ratio": str(latest.get("èµ„äº§è´Ÿå€ºç‡", "N/A")),
                            "source": "em"
                        }
                        financial_ok = True
                        logger.info(f"[{code}] ä¸œè´¢è´¢åŠ¡æŒ‡æ ‡ fallback æˆåŠŸ")
                except Exception as e:
                    logger.warning(f"[{code}] ä¸œè´¢è´¢åŠ¡æŒ‡æ ‡ä¹Ÿå¤±è´¥: {e}")

            if not financial_ok:
                logger.warning(f"[{code}] è´¢åŠ¡æ•°æ®å…¨éƒ¨å¤±è´¥ï¼ŒF10 ä»…æœ‰ä¼°å€¼(PE/PBæ¥è‡ªè¡Œæƒ…)")

            # === B. ä¸šç»©é¢„æµ‹ (åŒèŠ±é¡ºï¼Œå¯é€‰) ===
            _rate_limited_sleep()
            try:
                df_fore = ak.stock_profit_forecast_ths(symbol=code)
                if df_fore is not None and not df_fore.empty:
                    summary = df_fore.head(1).to_dict('records')[0]
                    data["forecast"] = {
                        "rating": summary.get("è¯„çº§", "æ— "),
                        "target_price": summary.get("ç›®æ ‡ä»·æ ¼", "æ— "),
                        "avg_profit_change": summary.get("å¹³å‡å‡€åˆ©æ¶¦å˜åŠ¨å¹…", "N/A")
                    }
            except Exception:
                pass

            logger.info(f"âœ… [{code}] F10 åŸºæœ¬é¢æ•°æ®è·å–æˆåŠŸ (æ¥æº: {data['financial'].get('source', 'none')})")

        except Exception as e:
            logger.error(f"âŒ [{code}] F10 æ•°æ®è·å–å¤±è´¥: {e}")

        return data


# å…¨å±€å•ä¾‹
_fetcher = FundamentalFetcher()

def get_fundamental_data(code: str) -> Dict[str, Any]:
    return _fetcher.get_f10_data(code)


def get_industry_pe_median(code: str) -> Optional[float]:
    """è·å–ä¸ªè‚¡æ‰€å±è¡Œä¸šçš„ PE ä¸­ä½æ•°ï¼ˆL1å†…å­˜ -> L2 DB -> ç½‘ç»œï¼‰"""
    # L1: è¿›ç¨‹å†…å­˜
    if code in _industry_pe_cache:
        return _industry_pe_cache[code]

    # L2: SQLite ç¼“å­˜
    db = _get_db()
    if db:
        cached = db.get_cache('industry_pe', code, ttl_hours=_INDUSTRY_PE_TTL_HOURS)
        if cached and 'median_pe' in cached:
            val = cached['median_pe']
            _industry_pe_cache[code] = val
            logger.info(f"ğŸ’¾ [{code}] è¡Œä¸šPEä¸­ä½æ•°å‘½ä¸­ DB ç¼“å­˜: {val}")
            return val

    # L3: ç½‘ç»œè¯·æ±‚
    try:
        import akshare as ak
        import numpy as np

        # 1. è·å–ä¸ªè‚¡è¡Œä¸šåˆ†ç±»
        _rate_limited_sleep()
        info_df = ak.stock_individual_info_em(symbol=code)
        if info_df is None or info_df.empty:
            return None

        info_dict = dict(zip(info_df.iloc[:, 0], info_df.iloc[:, 1]))
        industry = info_dict.get('è¡Œä¸š')
        if not industry:
            return None

        # 2. è·å–è¡Œä¸šæˆåˆ†è‚¡
        _rate_limited_sleep()
        cons_df = ak.stock_board_industry_cons_em(symbol=industry)
        if cons_df is None or cons_df.empty:
            return None

        # 3. æå–æˆåˆ†è‚¡ PE
        pe_col = None
        for col_name in ['å¸‚ç›ˆç‡-åŠ¨æ€', 'å¸‚ç›ˆç‡', 'PE']:
            if col_name in cons_df.columns:
                pe_col = col_name
                break

        if pe_col is None:
            logger.debug(f"[{code}] è¡Œä¸š '{industry}' æˆåˆ†è‚¡è¡¨æ—  PE åˆ—ï¼Œåˆ—å: {list(cons_df.columns)}")
            return None

        pe_values = cons_df[pe_col].apply(lambda x: float(x) if x not in (None, '', '-', 'nan') else None)
        pe_values = pe_values.dropna()
        pe_values = pe_values[(pe_values > 0) & (pe_values < 10000)]

        if len(pe_values) < 5:
            logger.debug(f"[{code}] è¡Œä¸š '{industry}' æœ‰æ•ˆ PE æ•°é‡ä¸è¶³({len(pe_values)})")
            return None

        median_pe = round(float(np.median(pe_values)), 2)
        logger.info(f"[{code}] è¡Œä¸š '{industry}' PEä¸­ä½æ•°={median_pe} (æ ·æœ¬{len(pe_values)})")

        # å›å†™ç¼“å­˜ï¼ˆåŒè¡Œä¸šæ‰€æœ‰æˆåˆ†è‚¡å…±äº«ï¼‰
        cache_val = {'median_pe': median_pe, 'industry': industry}
        if db:
            if 'ä»£ç ' in cons_df.columns:
                for _, row in cons_df.iterrows():
                    peer_code = str(row['ä»£ç '])
                    _industry_pe_cache[peer_code] = median_pe
                    db.set_cache('industry_pe', peer_code, cache_val)
            db.set_cache('industry_pe', code, cache_val)
        _industry_pe_cache[code] = median_pe
        return median_pe

    except Exception as e:
        logger.debug(f"[{code}] è¡Œä¸šPEä¸­ä½æ•°è·å–å¤±è´¥: {e}")
        return None