# -*- coding: utf-8 -*-
"""
===================================
Aè‚¡è‡ªé€‰è‚¡æ™ºèƒ½åˆ†æç³»ç»Ÿ - ä¸»è°ƒåº¦ç¨‹åº
===================================
"""
import os
from src.config import setup_env
setup_env()

# ä»£ç†é…ç½®
if os.getenv("GITHUB_ACTIONS") != "true" and os.getenv("USE_PROXY", "false").lower() == "true":
    proxy_host = os.getenv("PROXY_HOST", "127.0.0.1")
    proxy_port = os.getenv("PROXY_PORT", "10809")
    proxy_url = f"http://{proxy_host}:{proxy_port}"
    os.environ["http_proxy"] = proxy_url
    os.environ["https_proxy"] = proxy_url

import argparse
import logging
import sys
import time
import uuid
from datetime import datetime, timezone, timedelta
from logging.handlers import RotatingFileHandler
from pathlib import Path
from typing import List, Optional
from src.feishu_doc import FeishuDocManager

from src.config import get_config, Config
from src.notification import NotificationService
from src.core.pipeline import StockAnalysisPipeline
from src.core.market_review import run_market_review
from src.search_service import SearchService
from src.analyzer import GeminiAnalyzer

# é…ç½®æ—¥å¿—æ ¼å¼
LOG_FORMAT = '%(asctime)s | %(levelname)-8s | %(name)-20s | %(message)s'
LOG_DATE_FORMAT = '%Y-%m-%d %H:%M:%S'

def setup_logging(debug: bool = False, log_dir: str = "./logs") -> None:
    level = logging.DEBUG if debug else logging.INFO
    log_path = Path(log_dir)
    log_path.mkdir(parents=True, exist_ok=True)
    
    today_str = datetime.now().strftime('%Y%m%d')
    log_file = log_path / f"stock_analysis_{today_str}.log"
    debug_log_file = log_path / f"stock_analysis_debug_{today_str}.log"
    
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.DEBUG)
    
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(level)
    console_handler.setFormatter(logging.Formatter(LOG_FORMAT, LOG_DATE_FORMAT))
    root_logger.addHandler(console_handler)
    
    file_handler = RotatingFileHandler(log_file, maxBytes=10*1024*1024, backupCount=5, encoding='utf-8')
    file_handler.setLevel(logging.INFO)
    file_handler.setFormatter(logging.Formatter(LOG_FORMAT, LOG_DATE_FORMAT))
    root_logger.addHandler(file_handler)
    
    debug_handler = RotatingFileHandler(debug_log_file, maxBytes=50*1024*1024, backupCount=3, encoding='utf-8')
    debug_handler.setLevel(logging.DEBUG)
    debug_handler.setFormatter(logging.Formatter(LOG_FORMAT, LOG_DATE_FORMAT))
    root_logger.addHandler(debug_handler)
    
    logging.getLogger('urllib3').setLevel(logging.WARNING)
    logging.getLogger('sqlalchemy').setLevel(logging.WARNING)
    logging.getLogger('google').setLevel(logging.WARNING)
    logging.getLogger('httpx').setLevel(logging.WARNING)
    
    logging.info(f"æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼Œç›®å½•: {log_path.absolute()}")

logger = logging.getLogger(__name__)

def parse_arguments() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description='Aè‚¡è‡ªé€‰è‚¡æ™ºèƒ½åˆ†æç³»ç»Ÿ')
    parser.add_argument('--debug', action='store_true', help='å¯ç”¨è°ƒè¯•æ¨¡å¼')
    parser.add_argument('--dry-run', action='store_true', help='ä»…è·å–æ•°æ®')
    parser.add_argument('--stocks', type=str, help='æŒ‡å®šåˆ†æè‚¡ç¥¨ä»£ç ')
    parser.add_argument('--no-notify', action='store_true', help='ä¸å‘é€æ¨é€')
    parser.add_argument('--single-notify', action='store_true', help='å•è‚¡æ¨é€æ¨¡å¼')
    parser.add_argument('--workers', type=int, default=1, help='å¹¶å‘çº¿ç¨‹æ•°ï¼ˆé»˜è®¤1å³é¡ºåºè¾“å‡ºï¼‰')
    parser.add_argument('--schedule', action='store_true', help='å¯ç”¨å®šæ—¶ä»»åŠ¡')
    parser.add_argument('--market-review', action='store_true', help='ä»…å¤§ç›˜å¤ç›˜')
    parser.add_argument('--no-market-review', action='store_true', help='è·³è¿‡å¤§ç›˜å¤ç›˜')
    parser.add_argument('--webui', action='store_true', help='å¯åŠ¨WebUI')
    parser.add_argument('--webui-only', action='store_true', help='ä»…WebUI')
    parser.add_argument('--serve', action='store_true', help='å¯åŠ¨ FastAPI åç«¯æœåŠ¡ï¼ˆåŒæ—¶æ‰§è¡Œåˆ†æä»»åŠ¡ï¼‰')
    parser.add_argument('--serve-only', action='store_true', help='ä»…å¯åŠ¨ FastAPI åç«¯æœåŠ¡ï¼Œä¸è‡ªåŠ¨æ‰§è¡Œåˆ†æ')
    parser.add_argument('--host', type=str, default='0.0.0.0', help='FastAPI ç›‘å¬åœ°å€')
    parser.add_argument('--port', type=int, default=8000, help='FastAPI æœåŠ¡ç«¯å£')
    parser.add_argument('--no-context-snapshot', action='store_true', help='ä¸ä¿å­˜å¿«ç…§')
    parser.add_argument('--chip-only', action='store_true', help='ä»…æ‹‰å–ç­¹ç åˆ†å¸ƒå¹¶è½åº“ï¼ˆä¾›å®šæ—¶ä»»åŠ¡åœ¨å›ºå®šæ—¶é—´è·‘ï¼Œåˆ†ææ—¶ç”¨ç¼“å­˜ï¼‰')
    parser.add_argument('--fast', action='store_true', help='ç›˜ä¸­å¿«é€Ÿæ¨¡å¼ï¼šè·³è¿‡å¤–éƒ¨æœç´¢ã€ç”¨ç¼“å­˜èˆ†æƒ…ã€å¼ºåˆ¶è½»é‡æ¨¡å‹ã€è·³è¿‡F10')
    parser.add_argument('--backtest', action='store_true', help='å›æµ‹æ¨¡å¼ï¼šå›å¡«å†å²åˆ†æçš„å®é™…æ”¶ç›Šç‡å¹¶è¾“å‡ºèƒœç‡ç»Ÿè®¡')
    parser.add_argument('--daemon', action='store_true', help='å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼ï¼šå¯åŠ¨ WebUI + FastAPI + å®šæ—¶è°ƒåº¦ï¼Œä¸ç«‹å³åˆ†æ')
    return parser.parse_args()

def start_api_server(host: str, port: int, config: Config) -> None:
    """åœ¨åå°çº¿ç¨‹å¯åŠ¨ FastAPI æœåŠ¡ï¼ˆReact WebUI åç«¯ï¼‰"""
    import threading
    try:
        import uvicorn
    except ImportError:
        logger.error("è¯·å®‰è£… uvicorn: pip install uvicorn")
        return
    def run_server():
        level_name = (config.log_level or "INFO").lower()
        uvicorn.run(
            "api.app:app",
            host=host,
            port=port,
            log_level=level_name,
            log_config=None,
        )
    thread = threading.Thread(target=run_server, daemon=True)
    thread.start()
    logger.info(f"FastAPI æœåŠ¡å·²å¯åŠ¨: http://{host}:{port}")

def run_chip_only(config: Config) -> None:
    """ä»…æ‹‰å–ç­¹ç åˆ†å¸ƒå¹¶è½åº“ï¼ˆä¾›å®šæ—¶ä»»åŠ¡åœ¨ 16:00 ç­‰å›ºå®šæ—¶é—´è°ƒç”¨ï¼‰ã€‚"""
    config.refresh_stock_list()
    codes = config.stock_list
    if not codes:
        logger.warning("æœªé…ç½®è‡ªé€‰è‚¡åˆ—è¡¨ï¼Œè·³è¿‡ç­¹ç æ‹‰å–")
        return
    try:
        from data_provider import DataFetcherManager
    except ImportError:
        from data_provider.base import DataFetcherManager
    fetcher = DataFetcherManager()
    for i, code in enumerate(codes):
        try:
            chip = fetcher.get_chip_distribution(code, force_fetch=True)
            if chip:
                logger.info(f"[{i+1}/{len(codes)}] âœ… {code} ç­¹ç å·²æ‹‰å–å¹¶è½åº“")
            else:
                logger.debug(f"[{i+1}/{len(codes)}] {code} ç­¹ç æ‹‰å–è·³è¿‡/å¤±è´¥")
        except Exception as e:
            logger.warning(f"[{i+1}/{len(codes)}] {code} ç­¹ç æ‹‰å–å¼‚å¸¸: {e}")
        if i < len(codes) - 1:
            time.sleep(2)
    logger.info("ç­¹ç æ‹‰å–ä»»åŠ¡ç»“æŸ")


def run_full_analysis(config: Config, args: argparse.Namespace, stock_codes: Optional[List[str]] = None):
    """
    æ‰§è¡Œåˆ†ææµç¨‹ï¼ˆäº’æ–¥é€»è¾‘ä¼˜åŒ–ç‰ˆï¼‰
    """
    try:
        if getattr(args, 'single_notify', False):
            config.single_stock_notify = True
        if getattr(args, 'fast', False):
            config.fast_mode = True
        
        save_context_snapshot = None
        if getattr(args, 'no_context_snapshot', False):
            save_context_snapshot = False
        query_id = uuid.uuid4().hex
        
        pipeline = StockAnalysisPipeline(
            config=config,
            max_workers=args.workers,
            query_id=query_id,
            query_source="cli",
            save_context_snapshot=save_context_snapshot
        )
        
        results = []
        # === 1. è¿è¡Œä¸ªè‚¡åˆ†æ ===
        # é€»è¾‘ï¼šåªè¦ä¸æ˜¯"ä»…å¤§ç›˜å¤ç›˜"ï¼Œå°±è¿è¡Œä¸ªè‚¡
        if not args.market_review: 
            try:
                results = pipeline.run(
                    stock_codes=stock_codes,
                    dry_run=args.dry_run,
                    send_notification=not args.no_notify
                )
            except Exception as e:
                logger.error(f"âŒ ä¸ªè‚¡åˆ†ææµç¨‹å‘ç”Ÿå¼‚å¸¸: {e}")

        # === 2. è¿è¡Œå¤§ç›˜å¤ç›˜ ===
        # é€»è¾‘ï¼š
        # 1. å¿…é¡»å¼€å¯é…ç½®å¼€å…³
        # 2. å¿…é¡»æ²¡æœ‰æ˜¾å¼ç¦ç”¨ (--no-market-review)
        # 3. [å…³é”®ä¿®å¤] å¦‚æœæŒ‡å®šäº†ä¸ªè‚¡ (--stocks)ï¼Œåˆ™é»˜è®¤ä¸è·‘å¤§ç›˜ï¼Œé™¤éåŒæ—¶æŒ‡å®šäº† --market-review
        should_run_market = config.market_review_enabled and not args.no_market_review
        
        if stock_codes and not args.market_review:
            # å¦‚æœæŒ‡å®šäº†ä¸ªè‚¡ï¼Œä¸”æ²¡å¼ºåˆ¶è¦æ±‚è·‘å¤§ç›˜ï¼Œåˆ™é™é»˜å…³é—­å¤§ç›˜å¤ç›˜
            should_run_market = False
            logger.info("å·²æŒ‡å®šä¸ªè‚¡åˆ†æï¼Œè‡ªåŠ¨è·³è¿‡å¤§ç›˜å¤ç›˜ã€‚")

        market_report = ""
        if should_run_market:
            # é—´éš”ç­‰å¾…
            if results and getattr(config, 'analysis_delay', 0) > 0:
                time.sleep(config.analysis_delay)

            logger.info("\n" + "="*40)
            logger.info("ğŸ“ˆ å¼€å§‹æ‰§è¡Œå¤§ç›˜å¤ç›˜åˆ†æ...")
            logger.info("="*40)
            
            try:
                market_report = run_market_review(
                    notifier=pipeline.notifier,
                    analyzer=pipeline.analyzer,
                    search_service=pipeline.search_service
                )
                if market_report:
                    logger.info("âœ… å¤§ç›˜å¤ç›˜å®Œæˆ")
            except Exception as e:
                logger.error(f"âŒ å¤§ç›˜å¤ç›˜æ‰§è¡Œå¤±è´¥: {e}")
        
        # æ‘˜è¦è¾“å‡º
        if results:
            logger.info("\n===== åˆ†æç»“æœæ‘˜è¦ =====")
            for r in sorted(results, key=lambda x: x.sentiment_score, reverse=True):
                emoji = r.get_emoji()
                logger.info(f"{emoji} {r.name}({r.code}): {r.operation_advice} | è¯„åˆ† {r.sentiment_score}")
        
        # é£ä¹¦æ–‡æ¡£ç”Ÿæˆ
        try:
            feishu_doc = FeishuDocManager()
            if feishu_doc.is_configured() and (results or market_report):
                tz_cn = timezone(timedelta(hours=8))
                now = datetime.now(tz_cn)
                doc_title = f"{now.strftime('%Y-%m-%d %H:%M')} å¤ç›˜æŠ¥å‘Š"
                
                full_content = ""
                if market_report:
                    full_content += f"# ğŸ“ˆ å¤§ç›˜å¤ç›˜\n\n{market_report}\n\n---\n\n"
                if results:
                    dashboard_content = pipeline.notifier.generate_dashboard_report(results)
                    full_content += f"# ğŸš€ ä¸ªè‚¡å†³ç­–ä»ªè¡¨ç›˜\n\n{dashboard_content}"
                
                doc_url = feishu_doc.create_daily_doc(doc_title, full_content)
                if doc_url:
                    logger.info(f"é£ä¹¦äº‘æ–‡æ¡£åˆ›å»ºæˆåŠŸ: {doc_url}")
                    if not args.no_notify:
                        pipeline.notifier.send(f"[{now.strftime('%H:%M')}] å¤ç›˜æ–‡æ¡£: {doc_url}")
        except Exception as e:
            logger.error(f"é£ä¹¦æ–‡æ¡£ç”Ÿæˆå¤±è´¥: {e}")
        
    except Exception as e:
        logger.exception(f"åˆ†ææµç¨‹æ‰§è¡Œå¤±è´¥: {e}")

def start_bot_stream_clients(config: Config):
    if config.dingtalk_stream_enabled:
        try:
            from bot.platforms import start_dingtalk_stream_background
            start_dingtalk_stream_background()
        except: pass
    if getattr(config, 'feishu_stream_enabled', False):
        try:
            from bot.platforms import start_feishu_stream_background
            start_feishu_stream_background()
        except: pass

def main() -> int:
    args = parse_arguments()
    config = get_config()
    setup_logging(debug=args.debug, log_dir=config.log_dir)
    
    logger.info("=" * 60)
    logger.info("Aè‚¡è‡ªé€‰è‚¡æ™ºèƒ½åˆ†æç³»ç»Ÿ å¯åŠ¨")
    logger.info("=" * 60)
    
    stock_codes = None
    if args.stocks:
        stock_codes = [c.strip() for c in args.stocks.split(',') if c.strip()]
        logger.info(f"æŒ‡å®šåˆ†æè‚¡ç¥¨: {stock_codes}")
    
    # WebUI é€»è¾‘
    start_webui = (args.webui or args.webui_only or config.webui_enabled) and os.getenv("GITHUB_ACTIONS") != "true"
    start_serve = (args.serve or args.serve_only) and os.getenv("GITHUB_ACTIONS") != "true"
    if start_webui:
        try:
            from webui import run_server_in_thread
            run_server_in_thread(host=config.webui_host, port=config.webui_port)
            start_bot_stream_clients(config)
        except Exception as e:
            logger.error(f"WebUI å¯åŠ¨å¤±è´¥: {e}")
    if start_serve:
        try:
            start_api_server(host=args.host, port=args.port, config=config)
        except Exception as e:
            logger.error(f"FastAPI æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
    
    if args.webui_only:
        try:
            while True: time.sleep(1)
        except KeyboardInterrupt: return 0
    if args.serve_only:
        logger.info("æ¨¡å¼: ä»… FastAPI æœåŠ¡")
        logger.info(f"API è¿è¡Œä¸­: http://{args.host}:{args.port} æ–‡æ¡£: http://{args.host}:{args.port}/docs")
        try:
            while True: time.sleep(1)
        except KeyboardInterrupt: return 0

    # ========== å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼: WebUI + FastAPI + å®šæ—¶è°ƒåº¦ï¼Œä¸ç«‹å³åˆ†æ ==========
    if args.daemon:
        logger.info("=" * 60)
        logger.info("æ¨¡å¼: å®ˆæŠ¤è¿›ç¨‹ (WebUI + API + å®šæ—¶è°ƒåº¦)")
        logger.info("=" * 60)
        # 1. å¯åŠ¨ WebUIï¼ˆå¦‚æœè¿˜æ²¡å¯åŠ¨ï¼‰
        if not start_webui:
            try:
                from webui import run_server_in_thread
                run_server_in_thread(host=config.webui_host, port=config.webui_port)
                start_bot_stream_clients(config)
                logger.info(f"WebUI å·²å¯åŠ¨: http://{config.webui_host}:{config.webui_port}")
            except Exception as e:
                logger.warning(f"WebUI å¯åŠ¨å¤±è´¥ï¼ˆå¯å¿½ç•¥ï¼‰: {e}")
        # 2. å¯åŠ¨ FastAPIï¼ˆå¦‚æœè¿˜æ²¡å¯åŠ¨ï¼‰
        if not start_serve:
            try:
                start_api_server(host=args.host, port=args.port, config=config)
            except Exception as e:
                logger.warning(f"FastAPI å¯åŠ¨å¤±è´¥ï¼ˆå¯å¿½ç•¥ï¼‰: {e}")
        # 3. å¯åŠ¨å®šæ—¶è°ƒåº¦ï¼ˆä¸ç«‹å³æ‰§è¡Œåˆ†æï¼‰
        from src.scheduler import Scheduler
        scheduler = Scheduler(schedule_time=config.schedule_time)
        scheduler.set_daily_task(
            lambda: run_full_analysis(config, args, stock_codes),
            run_immediately=False   # å…³é”®ï¼šä¸ç«‹å³åˆ†æ
        )
        if getattr(config, 'chip_schedule_time', None) and config.chip_schedule_time != config.schedule_time:
            scheduler.add_daily_job(config.chip_schedule_time, lambda: run_chip_only(config))
            logger.info(f"å·²æ³¨å†Œæ¯æ—¥ç­¹ç æ‹‰å–ä»»åŠ¡ï¼Œæ‰§è¡Œæ—¶é—´: {config.chip_schedule_time}")
        logger.info(f"å®šæ—¶åˆ†æä»»åŠ¡å·²æ³¨å†Œï¼Œæ¯æ—¥ {config.schedule_time} æ‰§è¡Œ")
        logger.info(f"API æ–‡æ¡£: http://{args.host}:{args.port}/docs")
        logger.info("æŒ‰ Ctrl+C é€€å‡º")
        scheduler.run()
        return 0

    try:
        # æ¨¡å¼-1: å›æµ‹
        if getattr(args, 'backtest', False):
            logger.info("æ¨¡å¼: å›æµ‹åˆ†æ")
            from src.backtest import BacktestRunner
            runner = BacktestRunner()
            report = runner.run(lookback_days=60)
            print(report)
            return 0

        # æ¨¡å¼0: ä»…æ‹‰å–ç­¹ç å¹¶è½åº“ï¼ˆå®šæ—¶åœ¨å›ºå®šæ—¶é—´è·‘ï¼Œåˆ†ææ—¶ CHIP_FETCH_ONLY_FROM_CACHE=true ç”¨ç¼“å­˜ï¼‰
        if getattr(args, 'chip_only', False):
            logger.info("æ¨¡å¼: ä»…æ‹‰å–ç­¹ç åˆ†å¸ƒå¹¶è½åº“")
            config.refresh_stock_list()
            codes = stock_codes or config.stock_list
            if not codes:
                logger.error("æœªé…ç½®è‡ªé€‰è‚¡åˆ—è¡¨")
                return 1
            try:
                from data_provider import DataFetcherManager
            except ImportError:
                from data_provider.base import DataFetcherManager
            fetcher = DataFetcherManager()
            for i, code in enumerate(codes):
                try:
                    chip = fetcher.get_chip_distribution(code, force_fetch=True)
                    if chip:
                        logger.info(f"[{i+1}/{len(codes)}] âœ… {code} ç­¹ç å·²æ‹‰å–å¹¶è½åº“")
                    else:
                        logger.debug(f"[{i+1}/{len(codes)}] {code} ç­¹ç æ‹‰å–è·³è¿‡/å¤±è´¥")
                except Exception as e:
                    logger.warning(f"[{i+1}/{len(codes)}] {code} ç­¹ç æ‹‰å–å¼‚å¸¸: {e}")
                if i < len(codes) - 1:
                    time.sleep(2)
            logger.info("ç­¹ç æ‹‰å–ä»»åŠ¡ç»“æŸ")
            return 0

        # æ¨¡å¼1: ä»…å¤§ç›˜å¤ç›˜
        if args.market_review:
            logger.info("æ¨¡å¼: ä»…å¤§ç›˜å¤ç›˜")
            # åˆå§‹åŒ–å¿…è¦ç»„ä»¶
            notifier = NotificationService()
            analyzer = GeminiAnalyzer(api_key=config.gemini_api_key)
            search_service = None
            if config.bocha_api_keys or config.tavily_api_keys:
                search_service = SearchService(bocha_keys=config.bocha_api_keys, tavily_keys=config.tavily_api_keys)
            
            run_market_review(notifier=notifier, analyzer=analyzer, search_service=search_service)
            return 0
        
        # æ¨¡å¼2: å®šæ—¶ä»»åŠ¡ï¼ˆå¯åŒæ—¶æ³¨å†Œï¼šæ¯æ—¥å›ºå®šæ—¶é—´æ‹‰å–ç­¹ç  + æ¯æ—¥åˆ†æ/æ¨é€ï¼‰
        if args.schedule or config.schedule_enabled:
            from src.scheduler import Scheduler
            scheduler = Scheduler(schedule_time=config.schedule_time)
            scheduler.set_daily_task(
                lambda: run_full_analysis(config, args, stock_codes),
                run_immediately=True
            )
            # è‹¥é…ç½®äº†ç­¹ç å®šæ—¶æ—¶é—´ä¸”ä¸ä¸»ä»»åŠ¡æ—¶é—´ä¸åŒï¼Œåˆ™å¢åŠ æ¯æ—¥ç­¹ç æ‹‰å–ä»»åŠ¡ï¼ˆå¦‚ 16:00 æ”¶ç›˜åï¼‰
            if getattr(config, 'chip_schedule_time', None) and config.chip_schedule_time != config.schedule_time:
                scheduler.add_daily_job(config.chip_schedule_time, lambda: run_chip_only(config))
                logger.info(f"å·²æ³¨å†Œæ¯æ—¥ç­¹ç æ‹‰å–ä»»åŠ¡ï¼Œæ‰§è¡Œæ—¶é—´: {config.chip_schedule_time}")
            scheduler.run()
            return 0
        
        # æ¨¡å¼3: æ­£å¸¸è¿è¡Œ
        run_full_analysis(config, args, stock_codes)
        
        if (start_webui or start_serve) and not (args.schedule or config.schedule_enabled):
            try:
                while True: time.sleep(1)
            except KeyboardInterrupt: pass
            
        return 0
        
    except KeyboardInterrupt:
        return 0
    except Exception as e:
        logger.exception(f"ç¨‹åºå¤±è´¥: {e}")
        return 1

if __name__ == "__main__":
    sys.exit(main())