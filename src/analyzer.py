# -*- coding: utf-8 -*-
import json
import logging
import time
from concurrent.futures import ThreadPoolExecutor, TimeoutError as FuturesTimeoutError
from dataclasses import dataclass
from typing import Optional, Dict, Any, List
from src.config import get_config
import warnings

warnings.filterwarnings("ignore")

try:
    from json_repair import repair_json
except ImportError:
    repair_json = None

logger = logging.getLogger(__name__)

# è‚¡ç¥¨åç§°æ˜ å°„ï¼ˆæ‰©å±•ï¼šA/æ¸¯/ç¾è‚¡ï¼‰
STOCK_NAME_MAP = {
    '600519': 'è´µå·èŒ…å°', '000001': 'å¹³å®‰é“¶è¡Œ', '300750': 'å®å¾·æ—¶ä»£',
    '002594': 'æ¯”äºšè¿ª', '600036': 'æ‹›å•†é“¶è¡Œ', '601318': 'ä¸­å›½å¹³å®‰',
    '000858': 'äº”ç²®æ¶²', '600276': 'æ’ç‘åŒ»è¯', '601012': 'éš†åŸºç»¿èƒ½',
    '002475': 'ç«‹è®¯ç²¾å¯†', '300059': 'ä¸œæ–¹è´¢å¯Œ', '002415': 'æµ·åº·å¨è§†',
    '600900': 'é•¿æ±Ÿç”µåŠ›', '601166': 'å…´ä¸šé“¶è¡Œ', '600028': 'ä¸­å›½çŸ³åŒ–',
    'AAPL': 'è‹¹æœ', 'TSLA': 'ç‰¹æ–¯æ‹‰', 'MSFT': 'å¾®è½¯', 'NVDA': 'è‹±ä¼Ÿè¾¾',
    '00700': 'è…¾è®¯æ§è‚¡', '03690': 'ç¾å›¢', '01810': 'å°ç±³é›†å›¢', '09988': 'é˜¿é‡Œå·´å·´',
}

@dataclass
class AnalysisResult:
    code: str
    name: str
    sentiment_score: int
    trend_prediction: str
    operation_advice: str
    decision_type: str = "hold"
    confidence_level: str = "ä¸­"
    dashboard: Optional[Dict[str, Any]] = None
    analysis_summary: str = ""
    risk_warning: str = ""
    raw_response: Optional[str] = None
    search_performed: bool = False
    success: bool = True
    error_message: Optional[str] = None
    current_price: float = 0.0
    market_snapshot: Optional[Dict[str, Any]] = None

    # æ‰©å±•å­—æ®µï¼ˆå†³ç­–ä»ªè¡¨ç›˜ v2ï¼Œå…¼å®¹ä¸Šæ¸¸ï¼‰
    trend_analysis: str = ""
    short_term_outlook: str = ""
    medium_term_outlook: str = ""
    technical_analysis: str = ""
    ma_analysis: str = ""
    volume_analysis: str = ""
    pattern_analysis: str = ""
    fundamental_analysis: str = ""
    sector_position: str = ""
    company_highlights: str = ""
    news_summary: str = ""
    market_sentiment: str = ""
    hot_topics: str = ""
    key_points: str = ""
    buy_reason: str = ""
    data_sources: str = ""
    change_pct: Optional[float] = None
    analysis_time: str = ""       # åˆ†ææ—¶é—´ (HH:MM)ï¼Œç›˜ä¸­å¤šæ¬¡åˆ†ææ—¶åŒºåˆ†
    # LLM ç‹¬ç«‹åˆ¤æ–­ï¼ˆä½œä¸ºå‚è€ƒï¼Œä¸è¦†ç›–é‡åŒ–å†³ç­–ï¼‰
    llm_score: Optional[int] = None       # LLM è‡ªå·±ç»™çš„è¯„åˆ† (0-100)
    llm_advice: str = ""                  # LLM è‡ªå·±çš„æ“ä½œå»ºè®®
    llm_reasoning: str = ""               # LLM ç»™å‡ºä¸Šè°ƒ/ä¸‹è°ƒç†ç”±

    def to_dict(self) -> Dict[str, Any]:
        return {
            'code': self.code, 'name': self.name,
            'sentiment_score': self.sentiment_score,
            'trend_prediction': self.trend_prediction,
            'operation_advice': self.operation_advice,
            'decision_type': self.decision_type,
            'confidence_level': self.confidence_level,
            'dashboard': self.dashboard,
            'analysis_summary': self.analysis_summary,
            'risk_warning': self.risk_warning,
            'success': self.success,
            'price': self.current_price
        }

    def get_core_conclusion(self) -> str:
        if self.dashboard and 'core_conclusion' in self.dashboard:
            return self.dashboard['core_conclusion'].get('one_sentence', self.analysis_summary)
        return self.analysis_summary

    def get_position_advice(self, has_position: bool = False) -> str:
        if self.dashboard and 'core_conclusion' in self.dashboard:
            pos = self.dashboard['core_conclusion'].get('position_advice', {})
            return pos.get('has_position', self.operation_advice) if has_position else pos.get('no_position', self.operation_advice)
        return self.operation_advice

    def get_sniper_points(self) -> Dict[str, str]:
        if self.dashboard and 'battle_plan' in self.dashboard:
            return self.dashboard['battle_plan'].get('sniper_points', {})
        return {}

    def get_checklist(self) -> List[str]:
        if self.dashboard and 'battle_plan' in self.dashboard:
            return self.dashboard['battle_plan'].get('action_checklist', [])
        return []

    def get_risk_alerts(self) -> List[str]:
        if self.dashboard and 'intelligence' in self.dashboard:
            return self.dashboard['intelligence'].get('risk_alerts', [])
        return []

    def get_emoji(self) -> str:
        emoji_map = {'ä¹°å…¥': 'ğŸŸ¢', 'åŠ ä»“': 'ğŸŸ¢', 'å¼ºçƒˆä¹°å…¥': 'ğŸ’š', 'æŒæœ‰': 'ğŸŸ¡',
                     'è§‚æœ›': 'âšª', 'å‡ä»“': 'ğŸŸ ', 'å–å‡º': 'ğŸ”´', 'å¼ºçƒˆå–å‡º': 'âŒ'}
        advice = (self.operation_advice or '').strip()
        if advice in emoji_map:
            return emoji_map[advice]
        for part in advice.replace('/', '|').split('|'):
            part = part.strip()
            if part in emoji_map:
                return emoji_map[part]
        s = self.sentiment_score
        return 'ğŸ’š' if s >= 80 else 'ğŸŸ¢' if s >= 65 else 'ğŸŸ¡' if s >= 55 else 'âšª' if s >= 45 else 'ğŸŸ ' if s >= 35 else 'ğŸ”´'

    def get_confidence_stars(self) -> str:
        return {'é«˜': 'â­â­â­', 'ä¸­': 'â­â­', 'ä½': 'â­'}.get(self.confidence_level, 'â­â­')

class GeminiAnalyzer:
    # ==========================
    # å¤šè§’è‰² System Prompts
    # ==========================
    
    # è§’è‰²1: å®è§‚ç­–ç•¥å¸ˆ (ç”¨äº Market Review)
    PROMPT_MACRO = """ä½ æ˜¯ä¸€ä½è§†é‡å®å¤§çš„ã€å®è§‚å¯¹å†²ç­–ç•¥å¸ˆã€‘ã€‚
ä½ çš„ä»»åŠ¡æ˜¯åˆ†æå¸‚åœºæ•´ä½“çš„â€œå¤©æ°”çŠ¶å†µâ€ã€‚
- å…³æ³¨æ ¸å¿ƒï¼šæµåŠ¨æ€§ã€å¤®è¡Œæ”¿ç­–ã€æ±‡ç‡æ³¢åŠ¨ã€å¸‚åœºæƒ…ç»ªã€èµšé’±æ•ˆåº”ã€‚
- è¾“å‡ºé£æ ¼ï¼šé«˜å±‹å»ºç“´ï¼Œä¸çº ç»“ç»†ææœ«èŠ‚ï¼Œç»™å‡ºæ˜ç¡®çš„ä»“ä½æ§åˆ¶å»ºè®®ï¼ˆå¦‚ï¼šè¿›æ”»/é˜²å®ˆ/ç©ºä»“ï¼‰ã€‚
"""

    # è§’è‰²2: è¡Œä¸šä¾¦æ¢ (ç”¨äº Search/Info Gathering)
    PROMPT_RESEARCHER = """ä½ æ˜¯ä¸€ä½æ•é”çš„ã€åŸºæœ¬é¢ä¾¦æ¢ã€‘ã€‚
ä½ çš„ä»»åŠ¡æ˜¯æŒ–æ˜è´¢æŠ¥èƒŒåçš„çœŸç›¸å’Œè¡Œä¸šç«äº‰æ ¼å±€ã€‚
- å…³æ³¨æ ¸å¿ƒï¼šæŠ¤åŸæ²³ã€ä¸šç»©å¢é•¿è´¨é‡ã€æ½œåœ¨é›·ç‚¹ã€ç«äº‰å¯¹æ‰‹åŠ¨æ€ã€‚
- è¾“å‡ºé£æ ¼ï¼šå®¢è§‚ã€æ•°æ®é©±åŠ¨ã€æœ‰ä¸€è¯´ä¸€ï¼Œä¸åšè¿‡åº¦çš„è¡Œæƒ…é¢„æµ‹ã€‚
"""

    # è§’è‰²3: åŸºé‡‘ç»ç† (æ ¸å¿ƒå†³ç­–è€… - ç”¨äºä¸ªè‚¡åˆ†æ)
    PROMPT_TRADER = """ä½ æ˜¯ä¸€ä½ç†æ€§ã€æ•°æ®é©±åŠ¨çš„è‚¡ç¥¨åˆ†æå¸ˆã€‚ç”¨å®¢è§‚ä¸“ä¸šçš„è¯­è¨€è¾“å‡ºåˆ†æï¼Œç¦æ­¢ä½¿ç”¨ã€Œæˆ‘ä½œä¸ºâ€¦ã€ç­‰äººç§°è¡¨è¿°ã€‚

## ä½ çš„èŒè´£ï¼ˆä¸¥æ ¼é™å®šï¼‰
æŠ€æœ¯é¢åˆ†æï¼ˆè¯„åˆ†/ä¹°å–ä¿¡å·/æ­¢æŸæ­¢ç›ˆ/ä»“ä½ï¼‰å·²ç”±é‡åŒ–æ¨¡å‹å®Œæˆï¼Œä½ **ä¸å¾—é‡å¤åˆ†ææˆ–è¦†ç›–**ã€‚
ä½ åªè´Ÿè´£ä»¥ä¸‹3ä»¶äº‹ï¼š
1. **èˆ†æƒ…è§£è¯»**ï¼šä»æ–°é—»/å…¬å‘Šä¸­æå–åˆ©å¥½åˆ©ç©ºï¼Œåˆ¤æ–­çŸ­æœŸå‚¬åŒ–æˆ–é£é™©äº‹ä»¶
2. **åŸºæœ¬é¢å®šæ€§**ï¼šç»“åˆF10è´¢åŠ¡æ•°æ®ï¼Œè¯„ä¼°å…¬å¸è´¨åœ°ã€è¡Œä¸šåœ°ä½ã€æˆé•¿æ€§
3. **ç»¼åˆç»“è®º**ï¼šå°†é‡åŒ–ä¿¡å· + èˆ†æƒ… + åŸºæœ¬é¢ä¸‰è€…èåˆï¼Œç»™å‡ºä¸€å¥è¯ç»“è®º

## å†³ç­–é€»è¾‘
- å¤§ç›˜ç¯å¢ƒ â†’ ä»“ä½ä¸Šé™ï¼ˆé¡ºåŠ¿é‡ä»“ï¼Œé€†åŠ¿è½»ä»“ï¼‰
- ä¸ªè‚¡é€»è¾‘ â†’ ä¹°å–æ–¹å‘ï¼ˆåŸºæœ¬é¢ä¼˜+æŠ€æœ¯é¢å¤šå¤´=å‡ºå‡»ï¼›åŸºæœ¬é¢å·®+æŠ€æœ¯é¢ç ´ä½=ç¦»åœºï¼‰
- æ•°æ®çŸ›ç›¾æ—¶ â†’ è¯šå®è¡¨è¾¾ä¸ç¡®å®šæ€§ï¼Œä¸è¦å¼ºè¡Œç»™ç»“è®º
- ä¼°å€¼çº¦æŸ â†’ PE>50éœ€é™æ¡£æ“ä½œ

## è¾“å‡ºè´¨é‡è¦æ±‚
- one_sentence å¿…é¡»å…·ä½“ã€æœ‰ä¿¡æ¯é‡ï¼Œç¦æ­¢æ¨¡æ¿åŒ–ï¼ˆå¦‚"è¯¥è‚¡åŸºæœ¬é¢è‰¯å¥½"è¿™ç§åºŸè¯ï¼‰
- å¦‚æœä¿¡æ¯ä¸è¶³ä»¥åˆ¤æ–­ï¼Œå†™"ä¿¡æ¯ä¸è¶³ï¼Œå»ºè®®è§‚æœ›"è€Œéç¼–é€ ç†ç”±
"""

    def __init__(self, api_key: Optional[str] = None):
        config = get_config()
        self._api_key = api_key or config.gemini_api_key
        self._model = None
        self._model_light = None  # å‘½ä¸­èˆ†æƒ…ç¼“å­˜æ—¶å¯é€‰ç”¨çš„è½»é‡æ¨¡å‹ï¼ˆå¦‚ 2.5 Flashï¼‰ï¼Œçœæˆæœ¬
        self._openai_client = None
        self._use_openai = False

        # åˆå§‹åŒ– Geminiï¼ˆä¸»æ¨¡å‹ + å¤‡é€‰æ¨¡å‹ + å¯é€‰ã€Œç¼“å­˜æ—¶è½»é‡æ¨¡å‹ã€ï¼‰
        self._model_fallback = None
        if self._api_key and "your_" not in self._api_key:
            try:
                import google.generativeai as genai
                genai.configure(api_key=self._api_key)
                self._model = genai.GenerativeModel(model_name=config.gemini_model)
                fb = getattr(config, "gemini_model_fallback", None)
                if fb and str(fb).strip() and str(fb).strip() != config.gemini_model:
                    self._model_fallback = genai.GenerativeModel(model_name=str(fb).strip())
                when_cached = getattr(config, "gemini_model_when_cached", None)
                if when_cached and when_cached.strip() and when_cached != config.gemini_model:
                    self._model_light = genai.GenerativeModel(model_name=when_cached.strip())
            except Exception:
                pass

        # åˆå§‹åŒ– OpenAI
        if (not self._model) and config.openai_api_key:
            try:
                from openai import OpenAI
                self._openai_client = OpenAI(api_key=config.openai_api_key, base_url=config.openai_base_url)
                self._use_openai = True
            except: pass

    def is_available(self) -> bool:
        return self._model is not None or self._openai_client is not None

    def analyze(
        self,
        context: Dict[str, Any],
        news_context: Optional[str] = None,
        role: str = "trader",
        market_overview: Optional[str] = None,
        use_light_model: bool = False,
    ) -> AnalysisResult:
        """
        æ‰§è¡Œåˆ†æ
        :param role: æŒ‡å®šè§’è‰² 'trader'(ä¸ªè‚¡), 'macro'(å¤§ç›˜), 'researcher'
        :param market_overview: å¤§ç›˜ç¯å¢ƒæ•°æ®
        :param use_light_model: True æ—¶è‹¥é…ç½®äº†è½»é‡æ¨¡å‹ï¼ˆå¦‚ 2.5 Flashï¼‰åˆ™ç”¨ä¹‹ï¼Œçœæˆæœ¬ã€é€‚åˆå‘½ä¸­èˆ†æƒ…ç¼“å­˜çš„åœºæ™¯
        """
        code = context.get('code', 'Unknown')
        name = context.get('stock_name') or STOCK_NAME_MAP.get(code, f'è‚¡ç¥¨{code}')
        
        if not self.is_available():
            return AnalysisResult(code, name, 50, "æœªçŸ¥", "APIæœªé…ç½®", success=False)

        try:
            # 1. é€‰æ‹© System Prompt
            system_prompt = self.PROMPT_TRADER
            if role == "macro": system_prompt = self.PROMPT_MACRO
            elif role == "researcher": system_prompt = self.PROMPT_RESEARCHER

            # 2. æ„å»º User Prompt (æ³¨å…¥ F10, è®°å¿†, ä»¥åŠæ–°å¢çš„å¤§ç›˜æ•°æ®)
            prompt = self._format_prompt(context, name, news_context, market_overview)
            
            response_text = ""
            
            # 3. è°ƒç”¨ APIï¼ˆGemini ä¼˜å…ˆï¼Œå¤±è´¥æ—¶å°è¯•å¤‡é€‰æ¨¡å‹å’Œ OpenAIï¼‰
            cfg = get_config()
            response_text = self._call_api_with_fallback(
                system_prompt, prompt, use_light_model, cfg
            )

            # 4. è§£æç»“æœ
            result = self._parse_response(response_text, code, name)
            result.raw_response = response_text
            result.search_performed = bool(news_context)
            result.current_price = context.get('price', 0)
            result.market_snapshot = self._build_market_snapshot(context)
            return result
            
        except Exception as e:
            logger.error(f"AIåˆ†æå¤±è´¥: {e}")
            return AnalysisResult(code, name, 50, "é”™è¯¯", "åˆ†æå‡ºé”™", success=False, error_message=str(e))

    def _call_api_with_fallback(
        self, system_prompt: str, prompt: str, use_light_model: bool, cfg: Any
    ) -> str:
        """ä¼˜å…ˆ Geminiï¼Œå¤±è´¥æ—¶ä¾æ¬¡å°è¯•å¤‡é€‰æ¨¡å‹ã€OpenAI"""
        full_prompt = f"{system_prompt}\n\n{prompt}"
        max_retries = max(1, getattr(cfg, "gemini_max_retries", 5))
        retry_delay = getattr(cfg, "gemini_retry_delay", 5.0)
        gemini_temp = getattr(cfg, "gemini_temperature", 0.7)
        gen_cfg = {"temperature": gemini_temp}
        api_timeout = getattr(cfg, "gemini_request_timeout", 120)  # å•æ¬¡è¯·æ±‚è¶…æ—¶(ç§’)

        def _is_retryable(e: Exception) -> bool:
            s = str(e).lower()
            return "499" in s or "timeout" in s or "deadline" in s or "closed" in s or "429" in s or "rate" in s or "resource" in s

        models_to_try = []
        if self._model and not self._use_openai:
            m = self._model_light if (use_light_model and self._model_light) else self._model
            models_to_try.append(("gemini", m, "ä¸»æ¨¡å‹"))
            if self._model_fallback and m != self._model_fallback:
                models_to_try.append(("gemini", self._model_fallback, "å¤‡é€‰æ¨¡å‹"))
        if self._openai_client:
            models_to_try.append(("openai", None, "OpenAI"))

        last_err = None
        for i, (api_type, model, label) in enumerate(models_to_try):
            for attempt in range(max_retries):
                try:
                    if api_type == "openai":
                        r = self._openai_client.chat.completions.create(
                            model=cfg.openai_model,
                            messages=[
                                {"role": "system", "content": system_prompt},
                                {"role": "user", "content": prompt},
                            ],
                            temperature=getattr(cfg, "openai_temperature", 0.7),
                            timeout=api_timeout,
                        )
                        return r.choices[0].message.content
                    else:
                        # ç”¨çº¿ç¨‹æ± åŒ…è£¹ generate_contentï¼Œé˜²æ­¢æ— é™æŒ‚èµ·
                        with ThreadPoolExecutor(max_workers=1) as _tp:
                            future = _tp.submit(model.generate_content, full_prompt, generation_config=gen_cfg)
                            try:
                                resp = future.result(timeout=api_timeout)
                                return resp.text
                            except FuturesTimeoutError:
                                raise TimeoutError(f"Gemini API è¯·æ±‚è¶…æ—¶ ({api_timeout}s)")
                except Exception as e:
                    last_err = e
                    if attempt < max_retries - 1 and _is_retryable(e):
                        wait = retry_delay * (attempt + 1)
                        logger.warning(f"Gemini {label} å¼‚å¸¸ï¼Œ{wait:.0f}s åé‡è¯• ({attempt + 1}/{max_retries}): {e}")
                        time.sleep(wait)
                    else:
                        logger.warning(f"{label} å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€å¯ç”¨æ¨¡å‹: {e}")
                        break
        if last_err:
            raise last_err
        raise RuntimeError("æ— å¯ç”¨ AI æ¨¡å‹")

    def _format_prompt(self, context: Dict[str, Any], name: str, news_context: Optional[str] = None, market_overview: Optional[str] = None) -> str:
        code = context.get('code', 'Unknown')

        # A. æŠ€æœ¯é¢æ•°æ® (é‡åŒ–æ¨¡å‹äº§å‡º - ä½¿ç”¨ç²¾ç®€ç‰ˆä¾› LLM)
        tech_report = context.get('technical_analysis_report_llm') or context.get('technical_analysis_report', 'æ— æ•°æ®')
        
        # B. åŸºæœ¬é¢æ•°æ® (F10 - ç²¾ç®€æ ¼å¼)
        f10 = context.get('fundamental', {})
        f10_str = "æš‚æ—  F10 æ•°æ®"
        if f10:
            fin = f10.get('financial', {})
            fore = f10.get('forecast', {})
            val = f10.get('valuation', {}) or {}
            pe = val.get('pe')
            pb = val.get('pb')
            peg = val.get('peg')
            total_mv = val.get('total_mv')
            parts = []
            if isinstance(pe, (int, float)) and pe > 0: parts.append(f"PE={pe:.1f}")
            if isinstance(pb, (int, float)) and pb > 0: parts.append(f"PB={pb:.2f}")
            if isinstance(peg, (int, float)) and peg > 0: parts.append(f"PEG={peg:.2f}")
            if isinstance(total_mv, (int, float)) and total_mv > 0:
                parts.append(f"å¸‚å€¼={total_mv/1e8:.0f}äº¿" if total_mv >= 1e8 else f"å¸‚å€¼={total_mv/1e4:.0f}ä¸‡")
            growth = fin.get('net_profit_growth', 'N/A')
            roe = fin.get('roe', 'N/A')
            if growth != 'N/A': parts.append(f"å‡€åˆ©å¢é€Ÿ={growth}%")
            if roe != 'N/A': parts.append(f"ROE={roe}%")
            rating = fore.get('rating')
            if rating and rating != 'æ— ': parts.append(f"è¯„çº§={rating}")
            f10_str = " | ".join(parts) if parts else "æš‚æ—  F10 æ•°æ®"

        # C. å†å²è®°å¿†
        history = context.get('history_summary')
        history_str = "è¿™æ˜¯ä½ ç¬¬ä¸€æ¬¡å…³æ³¨è¯¥è‚¡ç¥¨ã€‚"
        if history:
            history_str = f"""
**ä½ æ˜¨å¤©çš„è§‚ç‚¹ ({history.get('date')})**ï¼š
- æ ¸å¿ƒåˆ¤æ–­ï¼š{history.get('view')}
- é£é™©æç¤ºï¼š{history.get('advice')}
è¯·éªŒè¯æ˜¨å¤©çš„é€»è¾‘æ˜¯å¦è¢«å¸‚åœºéªŒè¯ï¼Ÿ
"""

        # D. å¤§ç›˜ç¯å¢ƒ
        market_str = market_overview if market_overview else "æœªæä¾›å¤§ç›˜æ•°æ®ï¼Œé»˜è®¤ä¸­æ€§/éœ‡è¡ã€‚"

        # ç­¹ç 
        chip_note = context.get('chip_note') or ""
        chip_line = f"\nç­¹ç : {chip_note}" if chip_note and chip_note != "æœªå¯ç”¨" else ""

        # æ¿å—ç›¸å¯¹å¼ºå¼±
        sec = context.get('sector_context') or {}
        sector_line = ""
        if sec.get('sector_name'):
            sp = sec.get('sector_pct')
            rel = sec.get('relative')
            sp_str = f"{sp:+.2f}%" if isinstance(sp, (int, float)) else "N/A"
            rel_str = f"{rel:+.2f}%" if isinstance(rel, (int, float)) else "N/A"
            sector_line = f"\næ¿å—: {sec.get('sector_name')} ä»Šæ—¥{sp_str} | ç›¸å¯¹æ¿å—{rel_str}"

        # ç›˜ä¸­/ç›˜å
        is_intraday = context.get('is_intraday', False)
        market_phase = context.get('market_phase', '')
        analysis_time = context.get('analysis_time', '')

        if is_intraday:
            phase_label = {"morning": "ä¸Šåˆç›˜ä¸­", "lunch_break": "åˆä¼‘", "afternoon": "ä¸‹åˆç›˜ä¸­"}.get(market_phase, "ç›˜ä¸­")
            time_label = f" ({analysis_time})" if analysis_time else ""
            header = f"# ç›˜ä¸­ç ”åˆ¤ï¼š{name} ({code}){time_label}\nâš ï¸ ä»¥ä¸‹ä¸º{phase_label}å³æ—¶æ•°æ®ï¼Œéæ”¶ç›˜æ•°æ®ã€‚ä¾§é‡çŸ­çº¿æ“ä½œå»ºè®®ã€‚"
        else:
            header = f"# åˆ†æï¼š{name} ({code})"

        # èˆ†æƒ…é¢„åˆ†ç±»æ ‡æ³¨ (P2)
        news_section = "æš‚æ— é‡å¤§æ–°é—»"
        if news_context and news_context.strip():
            news_section = f"""è¯·ä»ä»¥ä¸‹æ–°é—»ä¸­æå–ï¼š[åˆ©å¥½]å‚¬åŒ–å‰‚ã€[åˆ©ç©º]é£é™©ã€[ä¸­æ€§]ä¿¡æ¯ã€‚é€æ¡æ ‡æ³¨åç»™å‡ºèˆ†æƒ…æ€»ç»“ã€‚

{news_context}"""

        time_horizon_hint = "'çŸ­çº¿(æ—¥å†…)' æˆ– 'çŸ­çº¿(1-3æ—¥)'" if is_intraday else "'çŸ­çº¿(1-5æ—¥)' æˆ– 'ä¸­çº¿(1-4å‘¨)' æˆ– 'é•¿çº¿(1-3æœˆ)'"

        # ç»„è£…ç²¾ç®€ Prompt
        return f"""{header}

åŸºäºä»¥ä¸‹æ•°æ®ï¼Œå®Œæˆä½ çš„3é¡¹èŒè´£ï¼ˆèˆ†æƒ…è§£è¯»/åŸºæœ¬é¢å®šæ€§/ç»¼åˆç»“è®ºï¼‰ã€‚æŠ€æœ¯é¢åˆ†æå·²ç”±é‡åŒ–æ¨¡å‹å®Œæˆï¼Œä¸è¦é‡å¤ã€‚

## å¤§ç›˜ç¯å¢ƒï¼ˆä»“ä½æ»¤ç½‘ï¼‰
{market_str}

## å†å²å›æº¯
{history_str}

## é‡åŒ–æŠ€æœ¯é¢ï¼ˆå·²å®Œæˆï¼Œä¸å¾—ç¯¡æ”¹ï¼‰
{tech_report}

## åŸºæœ¬é¢ (F10)
{f10_str}{sector_line}{chip_line}

## èˆ†æƒ…
{news_section}

## JSON è¾“å‡ºåè®®
æœ€ç»ˆè¯„åˆ†/æ“ä½œå»ºè®®/æ­¢æŸ/ä»“ä½ç”±é‡åŒ–æ¨¡å‹ç¡®å®šã€‚ä½ ç»™å‡ºç‹¬ç«‹åˆ¤æ–­ä½œä¸ºå‚è€ƒï¼ˆ"é‡åŒ– vs AI"åŒè§†è§’ï¼‰ã€‚
åªè¾“å‡º JSONï¼Œä¸è¦ markdown ä»£ç å—åŒ…è£¹ã€‚å­—æ®µï¼š

stock_name, trend_prediction, time_horizon({time_horizon_hint}),
analysis_summary(è§£é‡Šé€»è¾‘ï¼Œä¸è¦æ¨¡æ¿åŒ–), risk_warning,
sentiment_score(0-100), operation_advice("ä¹°å…¥"/"æŒæœ‰"/"å–å‡º"/"è§‚æœ›"),
llm_score(åŒsentiment_score), llm_advice(åŒoperation_advice),
llm_reasoning(ä¸é‡åŒ–åˆ†æ­§åŸå› ï¼Œæ— åˆ†æ­§å†™"ä¸é‡åŒ–ç»“è®ºä¸€è‡´"),
confidence_reasoning(åˆ¤æ–­ç½®ä¿¡åº¦ï¼Œå¦‚"èˆ†æƒ…å……åˆ†ç½®ä¿¡åº¦é«˜"æˆ–"ç¼ºå°‘å…³é”®æ•°æ®ç½®ä¿¡åº¦ä½"),
dashboard: {{
  core_conclusion: {{
    one_sentence: "ä¸€å¥è¯ç»“è®ºï¼ˆå¿…é¡»å…·ä½“æœ‰ä¿¡æ¯é‡ï¼‰",
    position_advice: {{ no_position: "ç©ºä»“è€…å»ºè®®", has_position: "æŒä»“è€…å»ºè®®" }}
  }},
  intelligence: {{ risk_alerts: [], positive_catalysts: [], sentiment_summary: "", earnings_outlook: "" }},
  battle_plan: {{ sniper_points: {{ ideal_buy: ç”¨é‡åŒ–é”šç‚¹, stop_loss: ç”¨é‡åŒ–é”šç‚¹ }} }}
}}

### one_sentence è´¨é‡ç¤ºä¾‹ï¼š
âœ… "é‡åŒ–78åˆ†çœ‹å¤š+åŒ—å‘èµ„é‡‘è¿ç»­3æ—¥æµå…¥+Q3è¥æ”¶å¢é€Ÿ35%è¶…é¢„æœŸï¼Œä½†PE=45å€å¤„äºå†å²é«˜ä½éœ€æ³¨æ„å›è°ƒé£é™©"
âœ… "æŠ€æœ¯é¢MACDé‡‘å‰+KDJè¶…å–å…±æŒ¯çœ‹å¤šï¼Œä½†å…¬å¸åˆšå‘ç›ˆåˆ©é¢„è­¦ï¼Œå»ºè®®ç­‰è´¢æŠ¥è½åœ°å†ä»‹å…¥"
âŒ "è¯¥è‚¡åŸºæœ¬é¢è‰¯å¥½ï¼ŒæŠ€æœ¯é¢è¡¨ç°ä¸é”™ï¼Œå»ºè®®å…³æ³¨"ï¼ˆç¦æ­¢è¿™ç§åºŸè¯ï¼‰

å¼€å§‹åˆ†æï¼š
"""

    def _parse_response(self, response_text: str, code: str, name: str) -> AnalysisResult:
        def _s(v: Any) -> str:
            return str(v).strip() if v is not None else ""

        try:
            clean_text = response_text.replace('```json', '').replace('```', '').strip()
            start = clean_text.find('{')
            end = clean_text.rfind('}') + 1
            if start >= 0 and end > start:
                clean_text = clean_text[start:end]

            data = json.loads(repair_json(clean_text) if repair_json else clean_text)

            op_advice = data.get('operation_advice', 'è§‚æœ›')
            decision = 'hold'
            if 'ä¹°' in op_advice or 'åŠ ä»“' in op_advice:
                decision = 'buy'
            elif 'å–' in op_advice or 'å‡ä»“' in op_advice:
                decision = 'sell'

            result = AnalysisResult(
                code=code, name=data.get('stock_name', name),
                sentiment_score=int(data.get('sentiment_score', 50)),
                trend_prediction=data.get('trend_prediction', 'éœ‡è¡'),
                operation_advice=op_advice, decision_type=decision,
                confidence_level=data.get('confidence_level', 'ä¸­'),
                dashboard=data.get('dashboard', {}),
                analysis_summary=data.get('analysis_summary', ''),
                risk_warning=data.get('risk_warning', ''), success=True
            )
            # æ‰©å±•å­—æ®µï¼ˆä»ªè¡¨ç›˜ v2ï¼ŒLLM è‹¥è¿”å›åˆ™å¡«å……ï¼‰
            result.trend_analysis = _s(data.get('trend_analysis'))
            result.short_term_outlook = _s(data.get('short_term_outlook'))
            result.medium_term_outlook = _s(data.get('medium_term_outlook'))
            result.technical_analysis = _s(data.get('technical_analysis'))
            result.ma_analysis = _s(data.get('ma_analysis'))
            result.volume_analysis = _s(data.get('volume_analysis'))
            result.pattern_analysis = _s(data.get('pattern_analysis'))
            result.fundamental_analysis = _s(data.get('fundamental_analysis'))
            result.sector_position = _s(data.get('sector_position'))
            result.company_highlights = _s(data.get('company_highlights'))
            result.news_summary = _s(data.get('news_summary'))
            result.market_sentiment = _s(data.get('market_sentiment'))
            result.hot_topics = _s(data.get('hot_topics'))
            result.key_points = _s(data.get('key_points'))
            result.buy_reason = _s(data.get('buy_reason'))
            result.data_sources = _s(data.get('data_sources'))
            cp = data.get('change_pct')
            result.change_pct = float(cp) if cp is not None and cp != '' else None
            # LLM ç‹¬ç«‹åˆ¤æ–­å­—æ®µ
            llm_s = data.get('llm_score')
            if llm_s is not None:
                try:
                    result.llm_score = int(llm_s)
                except (ValueError, TypeError):
                    pass
            result.llm_advice = _s(data.get('llm_advice'))
            result.llm_reasoning = _s(data.get('llm_reasoning'))
            # ç½®ä¿¡åº¦è¯´æ˜ï¼ˆP2: ä¸ç¡®å®šæ€§è¡¨è¾¾ï¼‰
            cr = _s(data.get('confidence_reasoning'))
            if cr:
                # ä» confidence_reasoning æ¨æ–­ confidence_level
                if any(k in cr for k in ('é«˜', 'å……åˆ†', 'æ˜ç¡®')):
                    result.confidence_level = 'é«˜'
                elif any(k in cr for k in ('ä½', 'ä¸è¶³', 'ç¼ºå°‘')):
                    result.confidence_level = 'ä½'
            return result
        except Exception as e:
            return AnalysisResult(code, name, 50, "è§£æé”™", "äººå·¥æ ¸æŸ¥", success=True, error_message=str(e))

    def _format_price(self, value: Any) -> str:
        """æ ¼å¼åŒ–ä»·æ ¼/æ•°å€¼ä¸ºå±•ç¤ºç”¨å­—ç¬¦ä¸²"""
        if value is None: return 'N/A'
        try:
            return f"{float(value):.2f}"
        except (TypeError, ValueError):
            return 'N/A'

    def _format_percent(self, value: Any) -> str:
        """æ ¼å¼åŒ–æ¶¨è·Œå¹…ç­‰ç™¾åˆ†æ¯”"""
        if value is None: return 'N/A'
        try:
            return f"{float(value):.2f}%"
        except (TypeError, ValueError):
            return 'N/A'

    def _format_volume(self, value: Any) -> str:
        """æ ¼å¼åŒ–æˆäº¤é‡ï¼ˆå¯è½¬ä¸ºä¸‡æ‰‹ç­‰ï¼‰"""
        if value is None: return 'N/A'
        try:
            v = float(value)
            if v >= 1e8: return f"{v/1e8:.2f}äº¿"
            if v >= 1e4: return f"{v/1e4:.2f}ä¸‡"
            return f"{v:.0f}"
        except (TypeError, ValueError):
            return 'N/A'

    def _format_amount(self, value: Any) -> str:
        """æ ¼å¼åŒ–æˆäº¤é¢"""
        if value is None: return 'N/A'
        try:
            v = float(value)
            if v >= 1e8: return f"{v/1e8:.2f}äº¿"
            if v >= 1e4: return f"{v/1e4:.2f}ä¸‡"
            return f"{v:.0f}"
        except (TypeError, ValueError):
            return 'N/A'

    def _build_market_snapshot(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ„å»ºå½“æ—¥è¡Œæƒ…å¿«ç…§ï¼ˆæ¨é€ä¸­ã€Œå½“æ—¥è¡Œæƒ…ã€è¡¨æ ¼ç”¨ï¼‰"""
        today = context.get('today') or {}
        realtime = context.get('realtime') or {}
        yesterday = context.get('yesterday') or {}

        prev_close = yesterday.get('close')
        close = today.get('close')
        high = today.get('high')
        low = today.get('low')

        # ç”¨å®æ—¶è¡Œæƒ…è¦†ç›–å¯èƒ½è¿‡æ—¶çš„æ—¥çº¿æ•°æ®ï¼Œç¡®ä¿è¡¨æ ¼ä¸å½“å‰ä»·ä¸€è‡´
        rt_price = realtime.get('price')
        if rt_price and rt_price > 0:
            close = rt_price
        rt_high = realtime.get('high')
        if rt_high and rt_high > 0:
            high = max(float(high or 0), rt_high)
        rt_low = realtime.get('low')
        if rt_low and rt_low > 0:
            low = min(float(low or 999999), rt_low) if low and float(low) > 0 else rt_low
        rt_open = realtime.get('open_price')
        if rt_open and rt_open > 0:
            today['open'] = rt_open
        if realtime.get('pre_close') and realtime['pre_close'] > 0:
            prev_close = realtime['pre_close']

        amplitude = None
        change_amount = None
        if prev_close not in (None, 0) and high is not None and low is not None:
            try:
                amplitude = (float(high) - float(low)) / float(prev_close) * 100
            except (TypeError, ValueError, ZeroDivisionError):
                amplitude = None
        if prev_close is not None and close is not None:
            try:
                change_amount = float(close) - float(prev_close)
            except (TypeError, ValueError):
                change_amount = None

        is_intraday = context.get('is_intraday', False)
        snapshot = {
            "date": context.get('date', 'æœªçŸ¥'),
            "is_intraday": is_intraday,
            "close": self._format_price(close),
            "open": self._format_price(today.get('open')),
            "high": self._format_price(high),
            "low": self._format_price(low),
            "prev_close": self._format_price(prev_close),
            "pct_chg": self._format_percent(realtime.get('change_pct') if realtime.get('change_pct') is not None else today.get('pct_chg')),
            "change_amount": self._format_price(change_amount),
            "amplitude": self._format_percent(amplitude),
            "volume": self._format_volume(realtime.get('volume') or today.get('volume')),
            "amount": self._format_amount(realtime.get('amount') or today.get('amount')),
        }
        if realtime:
            src = realtime.get('source')
            if hasattr(src, 'value'):
                src = src.value
            snapshot.update({
                "price": self._format_price(realtime.get('price')),
                "volume_ratio": realtime.get('volume_ratio') if realtime.get('volume_ratio') is not None else 'N/A',
                "turnover_rate": self._format_percent(realtime.get('turnover_rate')),
                "source": src if src is not None else 'N/A',
            })
        return snapshot

    def chat(self, prompt: str) -> str:
        """é€šç”¨å¯¹è¯æ¥å£ (å¤§ç›˜å¤ç›˜ç”¨)"""
        if not self.is_available(): return "AIæœªé…ç½®"
        try:
            if self._use_openai:
                return self._openai_client.chat.completions.create(
                    model=get_config().openai_model,
                    messages=[
                        {"role": "system", "content": self.PROMPT_MACRO},
                        {"role": "user", "content": prompt}
                    ]
                ).choices[0].message.content
            
            # Gemini
            return self._model.generate_content(f"{self.PROMPT_MACRO}\n\n{prompt}").text
        except Exception as e:
            return f"ç”Ÿæˆé”™è¯¯: {e}"

def get_analyzer() -> GeminiAnalyzer:
    return GeminiAnalyzer()