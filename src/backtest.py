# -*- coding: utf-8 -*-
"""
===================================
å›æµ‹æ¨¡å— - éªŒè¯åˆ†æç³»ç»Ÿçš„å®é™…èƒœç‡
===================================

åŠŸèƒ½ï¼š
1. å›å¡« analysis_history ä¸­ 5 ä¸ªäº¤æ˜“æ—¥åçš„å®é™…æ”¶ç›Šç‡
2. æ£€æŸ¥æ­¢æŸ/æ­¢ç›ˆæ˜¯å¦è¢«è§¦å‘
3. è¾“å‡ºæŒ‰è¯„åˆ†æ®µä½çš„èƒœç‡/å¹³å‡æ”¶ç›Š/æ­¢æŸå‘½ä¸­ç‡ç»Ÿè®¡

ä½¿ç”¨ï¼špython main.py --backtest
"""

import logging
from datetime import datetime, timedelta, date
from typing import List, Dict, Any, Optional, Tuple

import pandas as pd
import numpy as np
from sqlalchemy import select, and_, text

from src.storage import DatabaseManager, AnalysisHistory

logger = logging.getLogger(__name__)


class BacktestRunner:
    """åˆ†æå›æµ‹å™¨ï¼šå›å¡«å®é™…æ”¶ç›Šå¹¶ç»Ÿè®¡èƒœç‡"""

    def __init__(self):
        self.db = DatabaseManager()

    def run(self, lookback_days: int = 60) -> str:
        """æ‰§è¡Œå›æµ‹ï¼Œè¿”å›ç»Ÿè®¡æŠ¥å‘Šæ–‡æœ¬"""
        logger.info("===== å¼€å§‹å›æµ‹åˆ†æ =====")
        
        # 1. æ‰¾åˆ°éœ€è¦å›å¡«çš„è®°å½•ï¼ˆcreated_at > 5 äº¤æ˜“æ—¥å‰ ä¸” backtest_filled=0ï¼‰
        unfilled = self._get_unfilled_records(lookback_days)
        if unfilled:
            logger.info(f"å‘ç° {len(unfilled)} æ¡å¾…å›å¡«è®°å½•")
            filled_count = self._backfill_records(unfilled)
            logger.info(f"æˆåŠŸå›å¡« {filled_count} æ¡")
        else:
            logger.info("æ— æ–°çš„å¾…å›å¡«è®°å½•")

        # 2. ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        report = self._generate_stats_report(lookback_days)
        logger.info("===== å›æµ‹åˆ†æå®Œæˆ =====")
        return report

    def _get_unfilled_records(self, lookback_days: int) -> List[AnalysisHistory]:
        """è·å–éœ€è¦å›å¡«çš„å†å²è®°å½•ï¼ˆ5ä¸ªäº¤æ˜“æ—¥å‰çš„ + æœªå›å¡«ï¼‰"""
        cutoff = datetime.now() - timedelta(days=lookback_days)
        # è‡³å°‘ 7 å¤©å‰çš„è®°å½•æ‰èƒ½å›å¡«ï¼ˆ5 ä¸ªäº¤æ˜“æ—¥ â‰ˆ 7 è‡ªç„¶æ—¥ï¼‰
        fill_deadline = datetime.now() - timedelta(days=7)
        
        with self.db.get_session() as session:
            results = session.execute(
                select(AnalysisHistory).where(
                    and_(
                        AnalysisHistory.created_at >= cutoff,
                        AnalysisHistory.created_at <= fill_deadline,
                        AnalysisHistory.backtest_filled == 0,
                    )
                ).order_by(AnalysisHistory.created_at)
            ).scalars().all()
            # Detach from session
            return [r for r in results]

    def _backfill_records(self, records: List[AnalysisHistory]) -> int:
        """å›å¡«å®é™…æ”¶ç›Šç‡ï¼ˆå«å¤šå‘¨æœŸï¼‰"""
        filled = 0
        for record in records:
            try:
                code = record.code
                analysis_date = record.created_at.date() if record.created_at else None
                if not analysis_date:
                    continue

                # è·å–åˆ†ææ—¥ä¹‹å 20 ä¸ªäº¤æ˜“æ—¥çš„ä»·æ ¼æ•°æ®ï¼ˆæ”¯æŒå¤šå‘¨æœŸå›æµ‹ï¼‰
                df = self._get_prices_after(code, analysis_date, days=25)
                if df is None or len(df) < 5:
                    continue

                # åˆ†ææ—¥çš„æ”¶ç›˜ä»·ï¼ˆç”¨ç¬¬ä¸€æ¡è®°å½•ï¼‰
                price_at_analysis = float(df.iloc[0]['close'])
                if price_at_analysis <= 0:
                    continue

                # å¤šå‘¨æœŸæ”¶ç›Šç‡ï¼š5æ—¥ã€10æ—¥ã€20æ—¥
                price_5d = float(df.iloc[4]['close']) if len(df) >= 5 else float(df.iloc[-1]['close'])
                actual_pct_5d = round((price_5d - price_at_analysis) / price_at_analysis * 100, 2)
                
                actual_pct_10d = None
                if len(df) >= 10:
                    price_10d = float(df.iloc[9]['close'])
                    actual_pct_10d = round((price_10d - price_at_analysis) / price_at_analysis * 100, 2)
                
                actual_pct_20d = None
                if len(df) >= 20:
                    price_20d = float(df.iloc[19]['close'])
                    actual_pct_20d = round((price_20d - price_at_analysis) / price_at_analysis * 100, 2)

                # æ£€æŸ¥æ­¢æŸ/æ­¢ç›ˆæ˜¯å¦è§¦å‘ï¼ˆåœ¨ 5 æ—¥å†…çš„æœ€ä½ä»·/æœ€é«˜ä»·ï¼‰
                lows_5d = df['low'].iloc[:5].astype(float)
                highs_5d = df['high'].iloc[:5].astype(float)
                
                hit_sl = 0
                hit_tp = 0
                if record.stop_loss and record.stop_loss > 0:
                    hit_sl = 1 if float(lows_5d.min()) <= record.stop_loss else 0
                if record.take_profit and record.take_profit > 0:
                    hit_tp = 1 if float(highs_5d.max()) >= record.take_profit else 0

                # è·å–åŒæœŸå¤§ç›˜æ”¶ç›Šç‡ï¼ˆç”¨äºè®¡ç®—alphaï¼‰
                benchmark_pct_5d = self._get_benchmark_return(analysis_date, 5)
                benchmark_pct_10d = self._get_benchmark_return(analysis_date, 10) if actual_pct_10d else None
                benchmark_pct_20d = self._get_benchmark_return(analysis_date, 20) if actual_pct_20d else None

                # æ›´æ–°è®°å½•ï¼ˆæ‰©å±•å¤šå‘¨æœŸæ•°æ®ï¼Œä½†æš‚å­˜åœ¨åŸå­—æ®µï¼Œé¿å…ä¿®æ”¹è¡¨ç»“æ„ï¼‰
                # å®é™…ç”Ÿäº§ä¸­åº”æ·»åŠ æ–°å­—æ®µï¼šactual_pct_10d, actual_pct_20d, benchmark_pct_5dç­‰
                self._update_record(
                    record.id, actual_pct_5d, hit_sl, hit_tp,
                    actual_pct_10d=actual_pct_10d,
                    actual_pct_20d=actual_pct_20d,
                    benchmark_pct_5d=benchmark_pct_5d,
                    benchmark_pct_10d=benchmark_pct_10d,
                    benchmark_pct_20d=benchmark_pct_20d
                )
                filled += 1

            except Exception as e:
                logger.debug(f"å›å¡« {record.code} ({record.created_at}) å¤±è´¥: {e}")
                continue

        return filled

    def _get_prices_after(self, code: str, after_date: date, days: int = 10) -> Optional[pd.DataFrame]:
        """ä» stock_daily è·å–æŒ‡å®šæ—¥æœŸä¹‹åçš„ä»·æ ¼æ•°æ®"""
        try:
            sql = text("""
                SELECT date, open, high, low, close, volume 
                FROM stock_daily
                WHERE code = :code AND date > :after_date
                ORDER BY date ASC
                LIMIT :limit
            """)
            with self.db.engine.connect() as conn:
                df = pd.read_sql(sql, conn, params={"code": code, "after_date": after_date, "limit": days})
            return df if not df.empty else None
        except Exception:
            return None

    def _get_benchmark_return(self, start_date: date, holding_days: int) -> Optional[float]:
        """è·å–åŸºå‡†ï¼ˆæ²ªæ·±300ï¼‰æ”¶ç›Šç‡
        
        Args:
            start_date: èµ·å§‹æ—¥æœŸ
            holding_days: æŒæœ‰å¤©æ•°
        
        Returns:
            åŸºå‡†æ”¶ç›Šç‡(%)ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            # ä» index_daily è¡¨è·å–æ²ªæ·±300æ•°æ®
            sql = text("""
                SELECT date, close
                FROM index_daily
                WHERE name = 'æ²ªæ·±300' AND date >= :start_date
                ORDER BY date ASC
                LIMIT :limit
            """)
            with self.db.engine.connect() as conn:
                df = pd.read_sql(sql, conn, params={"start_date": start_date, "limit": holding_days + 2})
            
            if df.empty or len(df) < holding_days:
                return None
            
            price_start = float(df.iloc[0]['close'])
            price_end = float(df.iloc[min(holding_days - 1, len(df) - 1)]['close'])
            
            if price_start <= 0:
                return None
            
            return round((price_end - price_start) / price_start * 100, 2)
        except Exception as e:
            logger.debug(f"è·å–åŸºå‡†æ”¶ç›Šç‡å¤±è´¥: {e}")
            return None

    def _update_record(self, record_id: int, actual_pct: float, hit_sl: int, hit_tp: int,
                      actual_pct_10d: Optional[float] = None,
                      actual_pct_20d: Optional[float] = None,
                      benchmark_pct_5d: Optional[float] = None,
                      benchmark_pct_10d: Optional[float] = None,
                      benchmark_pct_20d: Optional[float] = None):
        """æ›´æ–°å•æ¡å›æµ‹è®°å½•ï¼ˆå«å¤šå‘¨æœŸæ•°æ®ï¼‰
        
        æ³¨ï¼šå¤šå‘¨æœŸæ•°æ®æš‚å­˜åœ¨ raw_result JSON ä¸­ï¼Œé¿å…é¢‘ç¹ä¿®æ”¹è¡¨ç»“æ„
        """
        with self.db.get_session() as session:
            try:
                record = session.get(AnalysisHistory, record_id)
                if record:
                    record.actual_pct_5d = actual_pct
                    record.hit_stop_loss = hit_sl
                    record.hit_take_profit = hit_tp
                    record.backtest_filled = 1
                    
                    # æ‰©å±•å›æµ‹æ•°æ®å­˜å…¥ raw_resultï¼ˆJSONæ ¼å¼ï¼Œçµæ´»æ‰©å±•ï¼‰
                    try:
                        import json
                        raw = json.loads(record.raw_result) if record.raw_result else {}
                        backtest_ext = {
                            'actual_pct_10d': actual_pct_10d,
                            'actual_pct_20d': actual_pct_20d,
                            'benchmark_pct_5d': benchmark_pct_5d,
                            'benchmark_pct_10d': benchmark_pct_10d,
                            'benchmark_pct_20d': benchmark_pct_20d,
                            'alpha_5d': round(actual_pct - benchmark_pct_5d, 2) if benchmark_pct_5d is not None else None,
                            'alpha_10d': round(actual_pct_10d - benchmark_pct_10d, 2) if actual_pct_10d and benchmark_pct_10d else None,
                            'alpha_20d': round(actual_pct_20d - benchmark_pct_20d, 2) if actual_pct_20d and benchmark_pct_20d else None,
                        }
                        raw['backtest_metrics'] = backtest_ext
                        record.raw_result = json.dumps(raw, ensure_ascii=False)
                    except Exception:
                        pass  # raw_result æ›´æ–°å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
                    
                    session.commit()
            except Exception as e:
                session.rollback()
                logger.debug(f"æ›´æ–°å›æµ‹è®°å½• {record_id} å¤±è´¥: {e}")

    def _generate_stats_report(self, lookback_days: int) -> str:
        """ç”Ÿæˆå¢å¼ºç‰ˆå›æµ‹ç»Ÿè®¡æŠ¥å‘Šï¼ˆå«å¤æ™®ã€ä¿¡æ¯æ¯”ç‡ã€alphaç­‰ï¼‰"""
        with self.db.get_session() as session:
            cutoff = datetime.now() - timedelta(days=lookback_days)
            records = session.execute(
                select(AnalysisHistory).where(
                    and_(
                        AnalysisHistory.created_at >= cutoff,
                        AnalysisHistory.backtest_filled == 1,
                    )
                )
            ).scalars().all()

        if not records:
            return "æš‚æ— å¯ç»Ÿè®¡çš„å›æµ‹æ•°æ®ï¼ˆéœ€è¦è‡³å°‘è¿è¡Œ 7 å¤©åæ‰æœ‰å›å¡«æ•°æ®ï¼‰"

        # æŒ‰è¯„åˆ†æ®µä½åˆ†ç»„ç»Ÿè®¡
        buckets = {"85+": [], "70-84": [], "50-69": [], "<50": []}
        buy_records = []

        for r in records:
            score = r.sentiment_score or 50
            pct = r.actual_pct_5d
            if pct is None:
                continue

            if score >= 85:
                buckets["85+"].append(r)
            elif score >= 70:
                buckets["70-84"].append(r)
            elif score >= 50:
                buckets["50-69"].append(r)
            else:
                buckets["<50"].append(r)

            # "ä¹°å…¥"ç±»å»ºè®®çš„ç»Ÿè®¡
            advice = r.operation_advice or ""
            if "ä¹°" in advice or "åŠ ä»“" in advice:
                buy_records.append(r)

        lines = [
            f"## ğŸ“Š å›æµ‹ç»Ÿè®¡æŠ¥å‘Šï¼ˆè¿‘ {lookback_days} å¤©ï¼Œå…± {len(records)} æ¡å·²å›å¡«ï¼‰",
            "",
        ]

        # === 1. æ•´ä½“ä¸šç»©æ‘˜è¦ï¼ˆå«å¤æ™®ã€ä¿¡æ¯æ¯”ç‡ï¼‰ ===
        all_pcts = [r.actual_pct_5d for r in records if r.actual_pct_5d is not None]
        if all_pcts:
            sharpe, info_ratio, max_dd, calmar = self._calc_performance_metrics(records)
            total_avg = sum(all_pcts) / len(all_pcts)
            total_win = sum(1 for p in all_pcts if p > 0) / len(all_pcts) * 100
            
            lines.extend([
                "### ğŸ¯ æ•´ä½“ä¸šç»©æŒ‡æ ‡",
                "",
                "| æŒ‡æ ‡ | æ•°å€¼ | è¯´æ˜ |",
                "|------|------|------|",
                f"| å¹³å‡5æ—¥æ”¶ç›Š | **{total_avg:+.2f}%** | æ‰€æœ‰ä¿¡å·çš„å¹³å‡æ”¶ç›Šç‡ |",
                f"| èƒœç‡ | **{total_win:.1f}%** | ç›ˆåˆ©äº¤æ˜“å æ¯” |",
                f"| å¤æ™®æ¯”ç‡ | **{sharpe:.2f}** | é£é™©è°ƒæ•´åæ”¶ç›Šï¼Œ>1ä¼˜ç§€ |",
                f"| ä¿¡æ¯æ¯”ç‡ | **{info_ratio:.2f}** | ç›¸å¯¹åŸºå‡†çš„è¶…é¢æ”¶ç›Š/è·Ÿè¸ªè¯¯å·® |",
                f"| æœ€å¤§å›æ’¤ | **{max_dd:.2f}%** | å³°è°·æœ€å¤§è·Œå¹… |",
                f"| å¡ç›æ¯”ç‡ | **{calmar:.2f}** | å¹´åŒ–æ”¶ç›Š/æœ€å¤§å›æ’¤ï¼Œ>2ä¼˜ç§€ |",
                "",
                "---",
                "",
            ])

        # === 2. æŒ‰è¯„åˆ†æ®µä½åˆ†æï¼ˆå«alphaï¼‰ ===
        lines.append("### ğŸ“ˆ å„è¯„åˆ†æ®µä½è¡¨ç°")
        lines.append("")
        lines.append("| è¯„åˆ†æ®µä½ | è®°å½•æ•° | å¹³å‡æ”¶ç›Š | Alpha | èƒœç‡ | å¤æ™® | æ­¢æŸå‘½ä¸­ | æ­¢ç›ˆå‘½ä¸­ |")
        lines.append("|---------|--------|---------|-------|------|------|---------|---------|")
        
        for bucket_name, bucket_records in buckets.items():
            if not bucket_records:
                lines.append(f"| {bucket_name} | 0 | - | - | - | - | - | - |")
                continue
            
            pcts = [r.actual_pct_5d for r in bucket_records if r.actual_pct_5d is not None]
            if not pcts:
                lines.append(f"| {bucket_name} | {len(bucket_records)} | N/A | N/A | N/A | N/A | N/A | N/A |")
                continue

            avg_pct = sum(pcts) / len(pcts)
            win_rate = sum(1 for p in pcts if p > 0) / len(pcts) * 100
            
            # Alphaè®¡ç®—ï¼ˆè¶…é¢æ”¶ç›Š = ä¸ªè‚¡æ”¶ç›Š - åŸºå‡†æ”¶ç›Šï¼‰
            alphas = []
            for r in bucket_records:
                if r.actual_pct_5d is not None and r.raw_result:
                    try:
                        import json
                        raw = json.loads(r.raw_result)
                        alpha_5d = raw.get('backtest_metrics', {}).get('alpha_5d')
                        if alpha_5d is not None:
                            alphas.append(alpha_5d)
                    except Exception:
                        pass
            avg_alpha = sum(alphas) / len(alphas) if alphas else 0.0
            
            # å¤æ™®æ¯”ç‡ï¼ˆæ®µä½å†…ï¼‰
            bucket_sharpe = self._calc_sharpe_ratio(pcts)
            
            sl_hits = sum(1 for r in bucket_records if r.hit_stop_loss == 1)
            tp_hits = sum(1 for r in bucket_records if r.hit_take_profit == 1)
            sl_rate = sl_hits / len(bucket_records) * 100
            tp_rate = tp_hits / len(bucket_records) * 100

            lines.append(
                f"| {bucket_name} | {len(bucket_records)} | {avg_pct:+.2f}% | {avg_alpha:+.2f}% | {win_rate:.0f}% | {bucket_sharpe:.2f} | {sl_rate:.0f}% | {tp_rate:.0f}% |"
            )

        # === 3. ä¹°å…¥ä¿¡å·ä¸“é¡¹éªŒè¯ ===
        lines.append("")
        lines.append("---")
        lines.append("")
        if buy_records:
            buy_pcts = [r.actual_pct_5d for r in buy_records if r.actual_pct_5d is not None]
            if buy_pcts:
                buy_win = sum(1 for p in buy_pcts if p > 0) / len(buy_pcts) * 100
                buy_avg = sum(buy_pcts) / len(buy_pcts)
                buy_sharpe = self._calc_sharpe_ratio(buy_pcts)
                lines.append(f"### ğŸ’° ä¹°å…¥ä¿¡å·éªŒè¯")
                lines.append(f"- ä¹°å…¥ä¿¡å·æ€»æ•°: **{len(buy_records)}**")
                lines.append(f"- 5æ—¥èƒœç‡: **{buy_win:.1f}%**")
                lines.append(f"- å¹³å‡5æ—¥æ”¶ç›Š: **{buy_avg:+.2f}%**")
                lines.append(f"- å¤æ™®æ¯”ç‡: **{buy_sharpe:.2f}**")
        else:
            lines.append("### ğŸ’° ä¹°å…¥ä¿¡å·éªŒè¯")
            lines.append("*æš‚æ— ä¹°å…¥ä¿¡å·è®°å½•*")

        lines.extend([
            "",
            "---",
            "",
            "### ğŸ“Œ æŒ‡æ ‡è¯´æ˜",
            "- **å¤æ™®æ¯”ç‡**: é£é™©è°ƒæ•´åæ”¶ç›Šï¼Œè®¡ç®—å…¬å¼ = (å¹³å‡æ”¶ç›Š - æ— é£é™©åˆ©ç‡) / æ”¶ç›Šæ ‡å‡†å·®",
            "- **ä¿¡æ¯æ¯”ç‡**: ç›¸å¯¹åŸºå‡†çš„è¶…é¢æ”¶ç›Š/è·Ÿè¸ªè¯¯å·®ï¼Œè¡¡é‡ä¸»åŠ¨ç®¡ç†èƒ½åŠ›",
            "- **Alpha**: è¶…é¢æ”¶ç›Š = ä¸ªè‚¡æ”¶ç›Š - åŒæœŸæ²ªæ·±300æ”¶ç›Š",
            "- **å¡ç›æ¯”ç‡**: å¹´åŒ–æ”¶ç›Š/æœ€å¤§å›æ’¤ï¼Œè¡¡é‡é£é™©æ”¶ç›Šæ¯”",
        ])

        return "\n".join(lines)

    def _calc_sharpe_ratio(self, returns: List[float], rf_rate: float = 0.03) -> float:
        """è®¡ç®—å¤æ™®æ¯”ç‡
        
        Args:
            returns: æ”¶ç›Šç‡åˆ—è¡¨(%)
            rf_rate: æ— é£é™©åˆ©ç‡(å¹´åŒ–)ï¼Œé»˜è®¤3%
        
        Returns:
            å¤æ™®æ¯”ç‡
        """
        if not returns or len(returns) < 2:
            return 0.0
        
        returns_array = np.array(returns) / 100  # è½¬ä¸ºå°æ•°
        avg_return = np.mean(returns_array)
        std_return = np.std(returns_array, ddof=1)
        
        if std_return == 0:
            return 0.0
        
        # 5æ—¥æ”¶ç›Šç‡å¹´åŒ–ï¼šå‡è®¾1å¹´250ä¸ªäº¤æ˜“æ—¥ï¼Œ5æ—¥ä¸º1/50å¹´
        # å¹´åŒ–æ”¶ç›Š = 5æ—¥å¹³å‡æ”¶ç›Š * (250/5) = å¹³å‡æ”¶ç›Š * 50
        # å¹´åŒ–æ³¢åŠ¨ = 5æ—¥æ³¢åŠ¨ * sqrt(250/5) = æ³¢åŠ¨ * sqrt(50)
        rf_5d = rf_rate / 50  # æ— é£é™©åˆ©ç‡è½¬ä¸º5æ—¥
        sharpe = (avg_return - rf_5d) / std_return * np.sqrt(50)
        
        return round(sharpe, 2)

    def _calc_performance_metrics(self, records: List[AnalysisHistory]) -> Tuple[float, float, float, float]:
        """è®¡ç®—æ•´ä½“ä¸šç»©æŒ‡æ ‡ï¼šå¤æ™®ã€ä¿¡æ¯æ¯”ç‡ã€æœ€å¤§å›æ’¤ã€å¡ç›æ¯”ç‡
        
        Returns:
            (sharpe_ratio, information_ratio, max_drawdown, calmar_ratio)
        """
        returns = [r.actual_pct_5d for r in records if r.actual_pct_5d is not None]
        if not returns:
            return 0.0, 0.0, 0.0, 0.0
        
        # 1. å¤æ™®æ¯”ç‡
        sharpe = self._calc_sharpe_ratio(returns)
        
        # 2. ä¿¡æ¯æ¯”ç‡ = (ç­–ç•¥å¹³å‡æ”¶ç›Š - åŸºå‡†å¹³å‡æ”¶ç›Š) / è·Ÿè¸ªè¯¯å·®
        alphas = []
        for r in records:
            if r.actual_pct_5d is not None and r.raw_result:
                try:
                    import json
                    raw = json.loads(r.raw_result)
                    alpha_5d = raw.get('backtest_metrics', {}).get('alpha_5d')
                    if alpha_5d is not None:
                        alphas.append(alpha_5d)
                except Exception:
                    pass
        
        if alphas and len(alphas) >= 2:
            avg_alpha = np.mean(alphas)
            tracking_error = np.std(alphas, ddof=1)
            info_ratio = (avg_alpha / tracking_error * np.sqrt(50)) if tracking_error > 0 else 0.0
        else:
            info_ratio = 0.0
        
        # 3. æœ€å¤§å›æ’¤ï¼ˆç´¯è®¡æ”¶ç›Šæ›²çº¿çš„å³°è°·å·®ï¼‰
        cumulative = np.cumsum([r / 100 for r in returns])  # ç´¯è®¡æ”¶ç›Šç‡ï¼ˆå°æ•°ï¼‰
        running_max = np.maximum.accumulate(cumulative)
        drawdown = (cumulative - running_max) * 100  # è½¬å›ç™¾åˆ†æ¯”
        max_drawdown = abs(np.min(drawdown)) if len(drawdown) > 0 else 0.0
        
        # 4. å¡ç›æ¯”ç‡ = å¹´åŒ–æ”¶ç›Š / æœ€å¤§å›æ’¤
        avg_return = np.mean(returns)
        annual_return = avg_return * 50  # 5æ—¥æ”¶ç›Šå¹´åŒ–
        calmar = (annual_return / max_drawdown) if max_drawdown > 0 else 0.0
        
        return (
            round(sharpe, 2),
            round(info_ratio, 2),
            round(max_drawdown, 2),
            round(calmar, 2)
        )
