# -*- coding: utf-8 -*-
import logging
import time
import random
import os
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Any
from concurrent.futures import ThreadPoolExecutor, as_completed, TimeoutError as FuturesTimeoutError

# === å¯¼å…¥æ•°æ®æ¨¡å— (ä¿æŒå¥å£®æ€§) ===
try:
    from data_provider import DataFetcherManager
except ImportError:
    try:
        from data_provider.base import DataFetcherManager
    except ImportError:
        # å°è¯•ä» src å¯¼å…¥
        from src.data_provider.base import DataFetcherManager

# å°è¯•å¯¼å…¥ F10 æ•°æ®è·å–å™¨
try:
    from data_provider.fundamental_fetcher import get_fundamental_data
except ImportError:
    def get_fundamental_data(code): return {}

# å°è¯•å¯¼å…¥ å¤§ç›˜ç›‘æ§ (Market Monitor) â€” ä¸ªè‚¡åˆ†ææ—¶ä½œä¸ºã€Œä»“ä½ä¸Šé™/å‰ç½®æ»¤ç½‘ã€
def _load_market_monitor():
    try:
        from data_provider.market_monitor import market_monitor
        return market_monitor
    except ImportError:
        try:
            import sys
            from pathlib import Path
            root = Path(__file__).resolve().parents[2]
            if str(root) not in sys.path:
                sys.path.insert(0, str(root))
            from data_provider.market_monitor import market_monitor
            return market_monitor
        except ImportError:
            return None

market_monitor = _load_market_monitor()


class MarketPhase:
    """A è‚¡å¸‚åœºé˜¶æ®µï¼Œç›˜ä¸­åˆ†ææ—¶éœ€åŒºåˆ†"""
    PRE_MARKET = "pre_market"          # ç›˜å‰ (< 9:30)
    MORNING_SESSION = "morning"        # ä¸Šåˆäº¤æ˜“ (9:30-11:30)
    LUNCH_BREAK = "lunch_break"        # åˆä¼‘ (11:30-13:00)ï¼Œä»·æ ¼å†»ç»“
    AFTERNOON_SESSION = "afternoon"    # ä¸‹åˆäº¤æ˜“ (13:00-15:00)
    POST_MARKET = "post_market"        # ç›˜å (>= 15:00)


def get_market_phase() -> str:
    """è¿”å›å½“å‰ A è‚¡å¸‚åœºé˜¶æ®µ"""
    now = datetime.now()
    t = now.hour * 60 + now.minute  # è½¬åˆ†é’Ÿæ–¹ä¾¿æ¯”è¾ƒ
    if t < 9 * 60 + 30:
        return MarketPhase.PRE_MARKET
    if t < 11 * 60 + 30:
        return MarketPhase.MORNING_SESSION
    if t < 13 * 60:
        return MarketPhase.LUNCH_BREAK
    if t < 15 * 60:
        return MarketPhase.AFTERNOON_SESSION
    return MarketPhase.POST_MARKET


def is_market_intraday() -> bool:
    """åˆ¤æ–­å½“å‰æ˜¯å¦ä¸º A è‚¡ç›˜ä¸­ï¼ˆå«åˆä¼‘ï¼Œå› ä¸ºå°šæœªæ”¶ç›˜ï¼‰"""
    phase = get_market_phase()
    return phase in (MarketPhase.MORNING_SESSION, MarketPhase.LUNCH_BREAK, MarketPhase.AFTERNOON_SESSION)


def is_market_trading() -> bool:
    """åˆ¤æ–­å½“å‰æ˜¯å¦æ­£åœ¨äº¤æ˜“ï¼ˆä¸å«åˆä¼‘ï¼‰"""
    phase = get_market_phase()
    return phase in (MarketPhase.MORNING_SESSION, MarketPhase.AFTERNOON_SESSION)


# === å†…éƒ¨æ¨¡å—å¯¼å…¥ ===
from src.stock_analyzer import StockTrendAnalyzer
from src.analyzer import GeminiAnalyzer, AnalysisResult
from src.notification import NotificationService
from src.storage import DatabaseManager  
from src.search_service import SearchService
from src.enums import ReportType

logger = logging.getLogger(__name__)

class StockAnalysisPipeline:
    """
    è‚¡ç¥¨åˆ†ææµæ°´çº¿ (æœ€ç»ˆå®Œæ•´ä¿®å¤ç‰ˆ)
    é€‚é… main.py çš„ config ä¼ å‚è°ƒç”¨æ–¹å¼ï¼ŒåŒ…å«ä¸¤é˜¶æ®µæ‰§è¡Œå’Œé˜²å°å·é€»è¾‘
    """
    def __init__(self, config, max_workers=3, query_id=None, query_source="cli", save_context_snapshot=True, source_message=None, **kwargs):
        """
        åˆå§‹åŒ– - ä¸¥æ ¼é€‚é… main.py çš„è°ƒç”¨æ–¹å¼
        """
        self.config = config
        self.query_id = query_id
        self.query_source = query_source
        self.save_context_snapshot = save_context_snapshot
        self.source_message = source_message

        # é˜¶æ®µä¸€é¢„å–ç¼“å­˜ï¼šé¿å…é˜¶æ®µäºŒé‡å¤æ‹‰å–/é‡å¤æ‹¼æ¥
        # ç»“æ„ï¼š{ code: {"df": <DataFrame>, "quote": <RealtimeQuote>} }
        self._prefetch_cache: Dict[str, Dict[str, Any]] = {}
        
        # === 1. é»˜è®¤é¡ºåºæ‰§è¡Œï¼ˆworkers=1ï¼‰ï¼Œé¿å…å¤šçº¿ç¨‹æ—¥å¿—äº¤é”™ ===
        if max_workers is None:
            max_workers = 1
            
        # === 2. åˆå§‹åŒ–å„ä¸ªæœåŠ¡ç»„ä»¶ ===
        self.fetcher_manager = DataFetcherManager()
        self.trend_analyzer = StockTrendAnalyzer()
        
        # åˆå§‹åŒ– LLM (ç›´æ¥ä» config è¯»å– key)
        self.analyzer = GeminiAnalyzer(api_key=config.gemini_api_key)
        
        # åˆå§‹åŒ– é€šçŸ¥æœåŠ¡
        self.notifier = NotificationService(source_message=source_message)
        
        # åˆå§‹åŒ– æ•°æ®åº“
        self.storage = DatabaseManager() 
        
        # === 3. åˆå§‹åŒ–æœç´¢æœåŠ¡ & æ™ºèƒ½æµæ§ ===
        self.search_service = None
        has_search_key = False
        
        # æ£€æŸ¥æ˜¯å¦é…ç½®äº†ä»»ä½•ä¸€ç§æœç´¢ Key
        if (config.bocha_api_keys or config.tavily_api_keys or 
            config.serpapi_keys or os.getenv("PERPLEXITY_API_KEY")):
            
            self.search_service = SearchService(
                bocha_keys=config.bocha_api_keys,
                tavily_keys=config.tavily_api_keys,
                serpapi_keys=config.serpapi_keys
            )
            has_search_key = True

        # å¦‚æœå¯ç”¨äº†æœç´¢ï¼Œå¼ºåˆ¶é™åˆ¶å¹¶å‘æ•°ï¼Œé˜²æ­¢ 429 é”™è¯¯
        if has_search_key:
            self.max_workers = min(max_workers, 2)
            logger.info(f"ğŸ•µï¸  [æ·±åº¦æ¨¡å¼] æœç´¢æœåŠ¡å·²å¯ç”¨ï¼Œå¹¶å‘é™åˆ¶ä¸º: {self.max_workers}")
        else:
            self.max_workers = max_workers
            logger.info(f"ğŸš€ [æé€Ÿæ¨¡å¼] çº¯æœ¬åœ°åˆ†æï¼Œå¹¶å‘æ•°: {self.max_workers}")

        # å¤§ç›˜ç›‘æ§ï¼šç”¨äºä¸ªè‚¡åˆ†ææ—¶çš„ã€Œä»“ä½ä¸Šé™/å‰ç½®æ»¤ç½‘ã€ï¼ˆå¤§ç›˜å®šä»“ä½ï¼Œä¸ªè‚¡å®šæ–¹å‘ï¼‰
        self._market_monitor = market_monitor
        if self._market_monitor:
            logger.info("ğŸ“Š [å¤§ç›˜ç›‘æ§] å·²å¯ç”¨ï¼Œä¸ªè‚¡åˆ†æå°†æ³¨å…¥å¤§ç›˜ç¯å¢ƒä½œä¸ºå‰ç½®æ»¤ç½‘")
        else:
            logger.warning("ğŸ“Š [å¤§ç›˜ç›‘æ§] æœªåŠ è½½ï¼Œä¸ªè‚¡åˆ†æå°†ä¸æ³¨å…¥å¤§ç›˜ç¯å¢ƒï¼ˆè¯·æ£€æŸ¥ data_provider.market_monitor ä¸ akshareï¼‰")

    def fetch_and_save_stock_data(self, code: str) -> (bool, str, Any, Any):
        """è·å–æ•°æ®å¹¶è½åº“ï¼Œä¿è¯ä¸‹æ¬¡å¯åšã€Œå†å²+å®æ—¶ã€æ‹¼æ¥ã€‚

        è¿”å›: (success, msg, df, quote)
        """
        try:
            # 120å¤©æ•°æ®ç”¨äºè®¡ç®—è¶‹åŠ¿ï¼ˆæœ‰å†å²åˆ™ DB+å®æ—¶ç¼åˆï¼Œæ— å†å²åˆ™å…¨é‡æŠ“å–ï¼‰
            df = self.fetcher_manager.get_merged_data(code, days=120)
            if df is None or df.empty:
                return False, "è·å–æ•°æ®ä¸ºç©º", None, None
            # å†™å…¥/æ›´æ–°æ—¥çº¿åˆ° DBï¼Œåç»­ run æ‰èƒ½ç”¨å†å²åšç¼åˆï¼ŒæŠ€æœ¯é¢æ‰å’Œç°å®ä¸€è‡´
            try:
                n = self.storage.save_daily_data(df, code, data_source="pipeline")
                if n > 0:
                    logger.debug(f"[{code}] æ—¥çº¿è½åº“æ–°å¢ {n} æ¡")
            except Exception as e:
                logger.warning(f"[{code}] æ—¥çº¿è½åº“å¤±è´¥(ç»§ç»­åˆ†æ): {e}")
            quote = self.fetcher_manager.get_realtime_quote(code)
            if not quote:
                return False, "å®æ—¶è¡Œæƒ…è·å–å¤±è´¥", df, None
            return True, "Success", df, quote
        except Exception as e:
            return False, str(e), None, None

    def _get_cached_news_context(self, code: str, stock_name: str, hours: int = 6,
                                  limit: int = 5, provider: str = None,
                                  min_count: int = 1) -> str:
        """
        ä» news_intel ç¼“å­˜ä¸­è·å–æ–°é—»ä¸Šä¸‹æ–‡ã€‚

        Args:
            code: è‚¡ç¥¨ä»£ç 
            stock_name: è‚¡ç¥¨åç§°ï¼ˆä»…ç”¨äºæ—¥å¿—ï¼‰
            hours: ç¼“å­˜æ—¶é—´çª—å£ï¼ˆå°æ—¶ï¼‰
            limit: æœ€å¤šè¿”å›æ¡æ•°
            provider: æ•°æ®æ¥æºè¿‡æ»¤ï¼ˆ'akshare', 'perplexity', None=ä¸é™ï¼‰
            min_count: æœ€å°‘å‘½ä¸­æ¡æ•°ï¼Œä½äºæ­¤æ•°è§†ä¸ºæœªå‘½ä¸­

        Returns:
            æ ¼å¼åŒ–çš„æ–°é—»ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²ï¼Œæœªå‘½ä¸­è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        try:
            items = self.storage.get_recent_news(code, days=1, limit=limit, provider=provider)
            if not items:
                return ""
            cutoff = datetime.now() - timedelta(hours=hours)
            fresh = [n for n in items if getattr(n, "fetched_at", None) and n.fetched_at >= cutoff]
            if len(fresh) < min_count:
                return ""
            lines = []
            for i, n in enumerate(fresh[:limit]):
                title = (getattr(n, "title", "") or "").strip()
                snippet = (getattr(n, "snippet", "") or "").strip()
                source = (getattr(n, "source", "") or "").strip()
                pub = getattr(n, "published_date", None)
                pub_str = f" ({pub})" if pub else ""
                head = f"{i+1}. ã€{source}ã€‘{title}{pub_str}".strip()
                body = snippet
                lines.append(f"{head}\n{body}".strip())
            return "\n".join(lines) if lines else ""
        except Exception:
            return ""

    def _prepare_stock_context(self, code: str) -> Optional[Dict[str, Any]]:
        """å‡†å¤‡ AI åˆ†ææ‰€éœ€çš„ä¸Šä¸‹æ–‡æ•°æ®"""
        prefetched = self._prefetch_cache.get(code) if hasattr(self, "_prefetch_cache") else None
        quote = (prefetched or {}).get("quote") or self.fetcher_manager.get_realtime_quote(code)
        if not quote:
            logger.warning(f"[{code}] æ— æ³•è·å–å®æ—¶è¡Œæƒ…ï¼Œè·³è¿‡")
            return None
        stock_name = quote.name
        
        try:
            cache_df = (prefetched or {}).get("df")
            if cache_df is not None:
                daily_df = cache_df
            else:
                daily_df = self.fetcher_manager.get_merged_data(code, days=120)
                # å•è‚¡/API è·¯å¾„æ—  prefetchï¼Œæ‹¿åˆ°æ•°æ®åè½åº“ï¼Œä¸‹æ¬¡åŒä¸€åªè‚¡å¯ç›´æ¥ç”¨ DB ç¼“å­˜
                if daily_df is not None and not daily_df.empty:
                    try:
                        self.storage.save_daily_data(daily_df, code, data_source="pipeline")
                    except Exception as e:
                        logger.debug(f"[{code}] æ—¥çº¿è½åº“å¤±è´¥(ç»§ç»­åˆ†æ): {e}")
        except Exception as e:
            logger.warning(f"[{code}] è·å–åˆå¹¶æ•°æ®å¤±è´¥: {e}")
            daily_df = None

        tech_report = "æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡ŒæŠ€æœ¯åˆ†æ"
        tech_report_llm = "æ•°æ®ä¸è¶³"
        trend_analysis_dict = {}
        if daily_df is not None and not daily_df.empty:
            try:
                from src.stock_analyzer import StockTrendAnalyzer as _STA, MarketRegime
                # æ£€æµ‹å¸‚åœºç¯å¢ƒï¼ˆç”¨äºåŠ¨æ€è¯„åˆ†æƒé‡ï¼‰
                idx_pct = 0.0
                if self._market_monitor:
                    try:
                        snap = self._market_monitor.get_market_snapshot()
                        for idx in snap.get('indices', []):
                            if idx.get('name') == 'ä¸Šè¯æŒ‡æ•°':
                                idx_pct = float(idx.get('change_pct', 0))
                                break
                    except Exception:
                        pass
                regime = _STA.detect_market_regime(daily_df, idx_pct)
                # è·å–æŒ‡æ•°æ”¶ç›Šç‡åºåˆ—ï¼ˆä¾› Beta è®¡ç®—ï¼‰
                idx_ret = None
                try:
                    idx_ret = self.storage.get_index_returns("ä¸Šè¯æŒ‡æ•°", days=120)
                    if idx_ret.empty:
                        idx_ret = None
                except Exception:
                    pass
                # æ„å»ºä¼°å€¼å¿«ç…§ï¼ˆä»å®æ—¶è¡Œæƒ…æå– PE/PBï¼Œä» F10 ç¼“å­˜æå– PEGï¼‰
                _valuation = {}
                if quote:
                    if getattr(quote, 'pe_ratio', None) is not None:
                        _valuation['pe'] = quote.pe_ratio
                    if getattr(quote, 'pb_ratio', None) is not None:
                        _valuation['pb'] = quote.pb_ratio
                # å°è¯•ä» F10 ç¼“å­˜è·å– PEGï¼ˆç¼“å­˜å‘½ä¸­å…ç½‘ç»œè¯·æ±‚ï¼‰
                try:
                    _f10_cached = get_fundamental_data(code) if not getattr(self.config, 'fast_mode', False) else {}
                    if _f10_cached:
                        _f10_val = _f10_cached.get('valuation', {}) or {}
                        if 'peg' in _f10_val:
                            _valuation['peg'] = _f10_val['peg']
                        elif _valuation.get('pe') and _valuation['pe'] > 0:
                            growth_str = _f10_cached.get('financial', {}).get('net_profit_growth', 'N/A')
                            if growth_str not in ('N/A', '', '0', None):
                                try:
                                    growth_val = float(str(growth_str).replace('%', ''))
                                    if growth_val > 0:
                                        _valuation['peg'] = round(_valuation['pe'] / growth_val, 2)
                                except (ValueError, TypeError):
                                    pass
                except Exception:
                    pass
                # èµ„é‡‘é¢æ•°æ®ï¼ˆå¦‚æœ‰ï¼‰
                _capital_flow = {}
                try:
                    if hasattr(self.fetcher_manager, 'get_capital_flow'):
                        _capital_flow = self.fetcher_manager.get_capital_flow(code) or {}
                except Exception:
                    pass
                trend_result = self.trend_analyzer.analyze(daily_df, code, market_regime=regime, index_returns=idx_ret, valuation=_valuation or None, capital_flow=_capital_flow or None)
                if quote.price:
                    trend_result.current_price = quote.price
                tech_report = self.trend_analyzer.format_analysis(trend_result)
                tech_report_llm = self.trend_analyzer.format_for_llm(trend_result)
                trend_analysis_dict = trend_result.to_dict()
                trend_analysis_dict['market_regime'] = regime.value
            except Exception as e:
                logger.error(f"[{code}] æŠ€æœ¯åˆ†æç”Ÿæˆå¤±è´¥: {e}")

        # ç­¹ç æ•°æ®ï¼ˆå…ˆæŸ¥ DB/å†…å­˜ç¼“å­˜ï¼›å¤±è´¥æ—¶æ˜ç¡®æ ‡è®°ã€Œæš‚ä¸å¯ç”¨ã€é¿å…æ¨¡å‹çç¼–ï¼‰
        chip_data = {}
        chip_note = "æœªå¯ç”¨"
        if getattr(self.config, 'enable_chip_distribution', False) or getattr(self.config, 'chip_fetch_only_from_cache', False):
            chip = self.fetcher_manager.get_chip_distribution(code) if hasattr(self.fetcher_manager, 'get_chip_distribution') else None
            if chip:
                chip_data = chip.to_dict()
                # ç­¹ç ç¼“å­˜å¹´é¾„å‘Šè­¦ï¼šè¶…è¿‡ 48h æç¤ºæ•°æ®å¯èƒ½è¿‡æ—¶
                chip_age_note = ""
                try:
                    fetched_at = getattr(chip, 'fetched_at', None) or chip_data.get('fetched_at')
                    if fetched_at:
                        from datetime import datetime as _dt
                        if isinstance(fetched_at, str):
                            fetched_at = _dt.fromisoformat(fetched_at)
                        age_hours = (datetime.now() - fetched_at).total_seconds() / 3600
                        if age_hours > 48:
                            chip_age_note = f"ï¼ˆæ³¨æ„ï¼šç­¹ç æ•°æ®å·²ç¼“å­˜ {age_hours:.0f} å°æ—¶ï¼Œå¯èƒ½è¿‡æ—¶ï¼‰"
                except Exception:
                    pass
                chip_note = f"è§ä¸‹æ•°æ®{chip_age_note}"
            else:
                chip_note = "æš‚ä¸å¯ç”¨ï¼ˆæ¥å£å¤±è´¥æˆ–æœªæ‹‰å–ï¼‰"
        
        # F10 åŸºæœ¬é¢æ•°æ®ï¼ˆå¿«é€Ÿæ¨¡å¼è·³è¿‡ï¼Œæ—¥å†…ä¸å˜ï¼Œç”¨ç¼“å­˜å³å¯ï¼‰
        fundamental_data = {}
        fast_mode = getattr(self.config, 'fast_mode', False)
        if not fast_mode:
            try:
                fundamental_data = get_fundamental_data(code)
            except Exception as e:
                pass
        # è¡¥å……ä¼°å€¼ï¼šä»å®æ—¶è¡Œæƒ…æ³¨å…¥ PE/PB/æ€»å¸‚å€¼ï¼ˆä¾›åŸºæœ¬é¢åˆ¤æ–­è´µ/ä¾¿å®œï¼‰
        if quote:
            val = fundamental_data.setdefault('valuation', {}) or {}
            if not isinstance(val, dict):
                fundamental_data['valuation'] = val = {}
            if getattr(quote, 'pe_ratio', None) is not None:
                val['pe'] = quote.pe_ratio
            if getattr(quote, 'pb_ratio', None) is not None:
                val['pb'] = quote.pb_ratio
            if getattr(quote, 'total_mv', None) is not None:
                val['total_mv'] = quote.total_mv

            # PEG = PE / å‡€åˆ©æ¶¦å¢é€Ÿï¼ˆæ­¤å¤„ä¸¤è€…éƒ½å·²å¯ç”¨ï¼Œæ¯” fundamental_fetcher é‡Œæ›´å¯é ï¼‰
            if 'peg' not in val:
                try:
                    pe = val.get('pe')
                    growth_str = fundamental_data.get('financial', {}).get('net_profit_growth', 'N/A')
                    if pe and isinstance(pe, (int, float)) and pe > 0 and growth_str not in ('N/A', '', '0', None):
                        growth_val = float(str(growth_str).replace('%', ''))
                        if growth_val > 0:
                            val['peg'] = round(pe / growth_val, 2)
                except (ValueError, TypeError, ZeroDivisionError):
                    pass

        # æ¿å—ç›¸å¯¹å¼ºå¼±
        sector_context = None
        try:
            stock_pct = getattr(quote, 'change_pct', None) if quote else None
            sector_context = self.fetcher_manager.get_stock_sector_context(code, stock_pct_chg=stock_pct)
        except Exception as e:
            logger.debug(f"[{code}] æ¿å—ä¸Šä¸‹æ–‡è·å–å¤±è´¥: {e}")

        # å†å²è®°å¿†
        history_summary = None
        try:
            history_summary = self.storage.get_last_analysis_summary(code)
        except Exception as e:
            pass

        # å½“æ—¥/æ˜¨æ—¥ K çº¿ï¼ˆä¾›æ¨é€ä¸­çš„ã€Œå½“æ—¥è¡Œæƒ…ã€å¿«ç…§ç”¨ï¼‰
        today_row = {}
        yesterday_row = {}
        context_date = ''
        if daily_df is not None and not daily_df.empty and len(daily_df) >= 1:
            try:
                keys = ['open', 'high', 'low', 'close', 'volume', 'amount', 'pct_chg', 'date']
                last = daily_df.iloc[-1]
                today_row = {k: last[k] for k in keys if k in last.index}
                context_date = str(today_row.get('date', ''))
                if len(daily_df) >= 2:
                    prev = daily_df.iloc[-2]
                    yesterday_row = {k: prev[k] for k in keys if k in prev.index}
            except Exception:
                pass

        context = {
            'code': code,
            'stock_name': stock_name,
            'date': context_date,
            'today': today_row,
            'yesterday': yesterday_row,
            'price': quote.price,
            'realtime': quote.to_dict(),
            'chip': chip_data,
            'chip_note': chip_note,
            'technical_analysis_report': tech_report,
            'technical_analysis_report_llm': tech_report_llm,
            'trend_analysis': trend_analysis_dict,
            'fundamental': fundamental_data,
            'history_summary': history_summary,
            'sector_context': sector_context,
            'is_intraday': is_market_intraday(),
            'market_phase': get_market_phase(),
            'analysis_time': datetime.now().strftime('%H:%M'),
        }
        context = self._enhance_context(context)
        return context

    def _enhance_context(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """å¢å¼º contextï¼šé¢„ç•™æ‰©å±•ç‚¹ï¼Œæœªæ¥å¯æ³¨å…¥é¢å¤–ç»“æ„åŒ–ä¿¡æ¯"""
        return context

    def _log(self, msg: str, *args, **kwargs) -> None:
        """å¸¦ query_id çš„æ—¥å¿—å‰ç¼€ï¼Œä¾¿äºé“¾è·¯è¿½è¸ª"""
        prefix = f"[query_id={self.query_id}] " if self.query_id else ""
        logger.info(prefix + msg, *args, **kwargs)

    def process_single_stock(
        self,
        code: str,
        skip_analysis: bool = False,
        single_stock_notify: bool = False,
        report_type: ReportType = ReportType.SIMPLE,
        skip_data_fetch: bool = False,
        market_overview_override: Optional[str] = None,
    ) -> Optional[AnalysisResult]:
        """å¤„ç†å•åªè‚¡ç¥¨çš„æ ¸å¿ƒé€»è¾‘"""
        try:
            context = self._prepare_stock_context(code)
            if not context: return None
            stock_name = context['stock_name']
            self._log(f"[{code}] {stock_name} å¼€å§‹åˆ†æ")
            
            if skip_analysis:
                logger.info(f"[{code}] Dry-run æ¨¡å¼ï¼Œè·³è¿‡ AI åˆ†æ")
                return AnalysisResult(code=code, name=stock_name, sentiment_score=50, trend_prediction="æµ‹è¯•", operation_advice="è§‚æœ›", analysis_summary="Dry Run æµ‹è¯•", success=True)

            # === 1. ä¸‰å±‚èˆ†æƒ…è·å– ===
            # ç¬¬ 1 å±‚: Akshare å…è´¹æ–°é—»ç¼“å­˜ (åå°å®šæ—¶æŠ“å–ï¼Œ24h çª—å£ï¼Œ>=2 æ¡å‘½ä¸­)
            # ç¬¬ 2 å±‚: Perplexity ç¼“å­˜ (6h çª—å£)
            # ç¬¬ 3 å±‚: Perplexity å®æ—¶æœç´¢ (æœ€åæ‰‹æ®µ)
            search_content = ""
            used_news_cache = False
            news_source = ""
            fast_mode = getattr(self.config, 'fast_mode', False)

            # å±‚ 1: Akshare å…è´¹æ–°é—»ï¼ˆåå°å·²æŠ“å–å…¥åº“ï¼‰
            akshare_news = self._get_cached_news_context(
                code, stock_name, hours=24, limit=10, provider='akshare', min_count=2
            )
            if akshare_news:
                search_content = akshare_news
                used_news_cache = True
                news_source = "akshare"
                logger.info(f"ğŸ“° [{stock_name}] å‘½ä¸­ Akshare æ–°é—»ç¼“å­˜ï¼Œè·³è¿‡å¤–éƒ¨æœç´¢")

            # å±‚ 2: Perplexity ç¼“å­˜ï¼ˆä¹‹å‰æœç´¢è¿‡çš„ç»“æœï¼‰
            if not search_content:
                pplx_cache = self._get_cached_news_context(
                    code, stock_name, hours=6, limit=5, provider='perplexity'
                )
                if pplx_cache:
                    search_content = pplx_cache
                    used_news_cache = True
                    news_source = "perplexity_cache"
                    logger.info(f"â™»ï¸  [{stock_name}] å‘½ä¸­ Perplexity ç¼“å­˜ï¼Œè·³è¿‡å¤–éƒ¨æœç´¢")

            # å±‚ 2.5: ä¸é™ provider çš„é€šç”¨ç¼“å­˜ï¼ˆå…¼å®¹æ—§æ•°æ®ï¼‰
            if not search_content:
                any_cache = self._get_cached_news_context(code, stock_name, hours=6, limit=5)
                if any_cache:
                    search_content = any_cache
                    used_news_cache = True
                    news_source = "cache_legacy"
                    logger.info(f"â™»ï¸  [{stock_name}] å‘½ä¸­èˆ†æƒ…ç¼“å­˜ï¼Œè·³è¿‡å¤–éƒ¨æœç´¢")

            # å¿«é€Ÿæ¨¡å¼ï¼šå³ä½¿æ— ç¼“å­˜ä¹Ÿä¸æœç´¢
            if not search_content and fast_mode:
                logger.info(f"âš¡ [{stock_name}] å¿«é€Ÿæ¨¡å¼ï¼Œè·³è¿‡å¤–éƒ¨æœç´¢")
                used_news_cache = True

            # å±‚ 3: Perplexity å®æ—¶æœç´¢ï¼ˆæœ€åæ‰‹æ®µï¼‰
            if not search_content and not fast_mode and self.search_service:
                sleep_time = random.uniform(2.0, 5.0)
                time.sleep(sleep_time)

                logger.info(f"ğŸ” [{stock_name}] æ— ç¼“å­˜æ–°é—»ï¼Œè°ƒç”¨ Perplexity æœç´¢ (å»¶è¿Ÿ {sleep_time:.1f}s)...")
                try:
                    if hasattr(self.search_service, 'search_comprehensive_intel'):
                        resp = self.search_service.search_comprehensive_intel(code, stock_name)
                    elif hasattr(self.search_service, 'search_stock_news'):
                        resp = self.search_service.search_stock_news(code, stock_name)
                    else:
                        resp = self.search_service.search(f"{stock_name} ({code}) è¿‘æœŸé‡å¤§åˆ©å¥½åˆ©ç©ºæ¶ˆæ¯ æœºæ„è§‚ç‚¹ ç ”æŠ¥")

                    if resp and getattr(resp, 'success', False):
                        search_content = resp.to_context()
                        news_source = "perplexity_live"
                        query = f"{stock_name} ({code}) ç»¼åˆåˆ†æ é£é™© ä¸šç»© è¡Œä¸š"
                        if getattr(resp, 'results', None):
                            try:
                                self.storage.save_news_intel(
                                    code, stock_name, dimension="èˆ†æƒ…", query=query, response=resp,
                                    query_context={"query_id": self.query_id, "query_source": self.query_source}
                                )
                            except Exception as e:
                                logger.debug(f"[{stock_name}] èˆ†æƒ…è½åº“è·³è¿‡: {e}")
                        else:
                            logger.warning(f"âš ï¸  [{stock_name}] Perplexity è¿”å›ç©ºç»“æœ")
                    else:
                        reason = getattr(resp, 'error', 'æœªçŸ¥') if resp else 'å“åº”ä¸ºç©º'
                        logger.warning(f"âš ï¸  [{stock_name}] Perplexity æœç´¢å¤±è´¥ (åŸå› : {reason})")
                except Exception as e:
                    logger.warning(f"[{stock_name}] æœç´¢æœåŠ¡å¼‚å¸¸: {e}")

            if not search_content and not fast_mode:
                logger.info(f"ğŸ“­ [{stock_name}] æ— èˆ†æƒ…æ•°æ®ï¼Œå°†ä»…åŸºäºæŠ€æœ¯é¢+åŸºæœ¬é¢åˆ†æ")

            # === 2. è·å–å¤§ç›˜ç¯å¢ƒï¼ˆå‰ç½®æ»¤ç½‘ï¼šå¤§ç›˜å®šä»“ä½ä¸Šé™ï¼Œä¸ªè‚¡é€»è¾‘å®šä¹°å–æ–¹å‘ï¼‰===
            # ç›˜ä¸­æ¨¡å¼ï¼šè‹¥å¤§ç›˜å¿«ç…§ç”±ä¸Šå±‚ä¼ å…¥ä½†å¸‚åœºä»åœ¨äº¤æ˜“ï¼Œåˆ·æ–°ä¸€æ¬¡ä»¥è·å–æœ€æ–°æ•°æ®
            market_overview = market_overview_override
            if market_overview is not None and is_market_trading() and self._market_monitor:
                try:
                    snapshot = self._market_monitor.get_market_snapshot()  # å†…éƒ¨æœ‰ 60s ç¼“å­˜ï¼Œä¸ä¼šæ‰“çˆ†æ¥å£
                    if snapshot.get('success'):
                        vol = snapshot.get('total_volume', 'N/A')
                        indices = snapshot.get('indices', [])
                        idx_str = " / ".join([f"{i['name']} {i['change_pct']}%" for i in indices])
                        market_overview = f"ä»Šæ—¥ä¸¤å¸‚æˆäº¤é¢: {vol}äº¿ã€‚æŒ‡æ•°è¡¨ç°: {idx_str}ã€‚ï¼ˆä»¥ä¸Šä¸º**ç›˜ä¸­æ•°æ®**ï¼Œæˆªè‡³å½“å‰ã€‚ï¼‰"
                except Exception:
                    pass  # åˆ·æ–°å¤±è´¥åˆ™æ²¿ç”¨ä¸Šå±‚ä¼ å…¥çš„æ—§å¿«ç…§
            if market_overview is None and self._market_monitor:
                try:
                    snapshot = self._market_monitor.get_market_snapshot()
                    if snapshot.get('success'):
                        vol = snapshot.get('total_volume', 'N/A')
                        indices = snapshot.get('indices', [])
                        idx_str = " / ".join([f"{i['name']} {i['change_pct']}%" for i in indices])
                        market_overview = f"ä»Šæ—¥ä¸¤å¸‚æˆäº¤é¢: {vol}äº¿ã€‚æŒ‡æ•°è¡¨ç°: {idx_str}ã€‚"
                        if is_market_intraday():
                            market_overview += "ï¼ˆä»¥ä¸Šä¸º**ç›˜ä¸­æ•°æ®**ï¼Œéæ”¶ç›˜ï¼›æˆäº¤é¢ä¸æ¶¨è·Œå¹…å‡ä¸ºæˆªè‡³å½“å‰ã€‚ï¼‰"
                        logger.info(f"ğŸ“Š [{stock_name}] å¤§ç›˜ç¯å¢ƒå·²æ³¨å…¥ï¼ˆæ»¤ç½‘ï¼‰: æˆäº¤é¢{vol}äº¿ | {idx_str}")
                except Exception as e:
                    logger.warning(f"[{stock_name}] è·å–å¤§ç›˜æ•°æ®å¾®ç‘•: {e}")

            # åˆ†æå‰å»¶è¿Ÿï¼ˆå¯é…ç½®ï¼Œç”¨äºç­‰å¾…æ•°æ®è½å®šæˆ–é™ä½ API å‹åŠ›ï¼‰
            delay = getattr(self.config, 'analysis_delay', 0) or 0
            if delay > 0:
                time.sleep(delay)
            self._log(f"ğŸ¤– [{stock_name}] è°ƒç”¨ LLM è¿›è¡Œåˆ†æ...")
            # æ— èˆ†æƒ…æ—¶ä¹Ÿç”¨è½»é‡æ¨¡å‹ï¼Œçœæˆæœ¬
            use_light = used_news_cache or (not search_content or not search_content.strip())
            # === 3. æ‰§è¡Œåˆ†æï¼ˆå¸¦è¶…æ—¶ï¼Œé»˜è®¤ 180 ç§’ï¼‰===
            analysis_timeout = getattr(self.config, 'analysis_timeout_seconds', 180) or 180
            def _run_analyze():
                return self.analyzer.analyze(
                    context=context,
                    news_context=search_content,
                    role="trader",
                    market_overview=market_overview,
                    use_light_model=use_light,
                )
            try:
                with ThreadPoolExecutor(max_workers=1) as ex:
                    fut = ex.submit(_run_analyze)
                    result = fut.result(timeout=analysis_timeout)
            except FuturesTimeoutError:
                logger.warning(f"[{stock_name}] åˆ†æè¶…æ—¶ ({analysis_timeout}s)ï¼Œè·³è¿‡")
                return None
            except Exception as e:
                logger.exception(f"[{stock_name}] åˆ†æå¼‚å¸¸: {e}")
                return None
            
            if not result: return None

            # ===== Quant Override: ç¡¬å†³ç­–ç”±é‡åŒ–æ¨¡å‹ä¸»å¯¼ï¼ŒLLM æ„è§ä¿ç•™ä½œå‚è€ƒ =====
            trend = context.get('trend_analysis', {})
            if trend and isinstance(trend, dict):
                quant_score = trend.get('signal_score')
                quant_signal = trend.get('buy_signal')
                # ä¿ç•™ LLM çš„åŸå§‹è¯„åˆ†å’Œå»ºè®®ä½œä¸ºå‚è€ƒ
                # llm_score/llm_advice å¯èƒ½ç”± _parse_response ä» JSON ç›´æ¥è§£æï¼›
                # è‹¥ LLM æ²¡æ˜¾å¼è¿”å›ï¼Œåˆ™ç”¨ LLM çš„ sentiment_score/operation_advice ä½œä¸º fallbackï¼ˆé‡åŒ–è¦†ç›–å‰ï¼‰
                if result.llm_score is None and result.sentiment_score is not None:
                    result.llm_score = result.sentiment_score
                if not result.llm_advice and result.operation_advice and result.operation_advice != 'è§‚æœ›':
                    result.llm_advice = result.operation_advice
                # å¦‚æœ LLM ä»€ä¹ˆéƒ½æ²¡è¿”å›ï¼ˆsentiment_score é»˜è®¤50ï¼‰ï¼Œä¸” llm_score ä»ä¸º 50ï¼Œæ ‡è®°æ¥æº
                # ç¡®ä¿ llm_advice æœ‰å€¼
                if not result.llm_advice and result.operation_advice:
                    result.llm_advice = result.operation_advice
                # é‡åŒ–æ¨¡å‹è¦†ç›–ä¸»å†³ç­–
                if quant_score is not None:
                    result.sentiment_score = int(quant_score)
                if quant_signal:
                    result.operation_advice = str(quant_signal)
                # æ­¢æŸ/ä¹°ç‚¹ï¼šç”¨é‡åŒ–é”šç‚¹è¦†ç›– LLM è¾“å‡º
                dashboard = result.dashboard or {}
                battle = dashboard.get('battle_plan', {})
                sniper = battle.get('sniper_points', {})
                if trend.get('stop_loss_short'):
                    sniper['stop_loss'] = trend['stop_loss_short']
                if trend.get('ideal_buy_anchor'):
                    sniper['ideal_buy'] = trend['ideal_buy_anchor']
                if trend.get('stop_loss_intraday'):
                    sniper['stop_loss_intraday'] = trend['stop_loss_intraday']
                if trend.get('stop_loss_mid'):
                    sniper['stop_loss_mid'] = trend['stop_loss_mid']
                battle['sniper_points'] = sniper
                dashboard['battle_plan'] = battle
                result.dashboard = dashboard
                # ä»“ä½
                if trend.get('suggested_position_pct') is not None:
                    # å†™å…¥ dashboard ä¾›æŠ¥å‘Šä½¿ç”¨
                    core = dashboard.get('core_conclusion', {})
                    pos = core.get('position_advice', {})
                    pct = trend['suggested_position_pct']
                    if pct == 0:
                        pos['no_position'] = "ä¸å»ºè®®ä»‹å…¥"
                    else:
                        pos['no_position'] = f"å»ºè®®ä»“ä½ {pct}%"
                    core['position_advice'] = pos
                    dashboard['core_conclusion'] = core

                # æ­¢ç›ˆç‚¹ä½æ³¨å…¥
                if trend.get('take_profit_short'):
                    sniper['take_profit'] = trend['take_profit_short']
                if trend.get('take_profit_mid'):
                    sniper['take_profit_mid'] = trend['take_profit_mid']

                # æ–°é‡åŒ–å­—æ®µæ³¨å…¥ dashboardï¼ˆä¾› notification æ¸²æŸ“ï¼‰
                quant_extras = {
                    'valuation_verdict': trend.get('valuation_verdict', ''),
                    'valuation_downgrade': trend.get('valuation_downgrade', 0),
                    'pe_ratio': trend.get('pe_ratio', 0),
                    'pb_ratio': trend.get('pb_ratio', 0),
                    'peg_ratio': trend.get('peg_ratio', 0),
                    'valuation_score': trend.get('valuation_score', 0),
                    'trading_halt': trend.get('trading_halt', False),
                    'trading_halt_reason': trend.get('trading_halt_reason', ''),
                    'capital_flow_score': trend.get('capital_flow_score', 0),
                    'capital_flow_signal': trend.get('capital_flow_signal', ''),
                    'beginner_summary': trend.get('beginner_summary', ''),
                    'take_profit_short': trend.get('take_profit_short', 0),
                    'take_profit_mid': trend.get('take_profit_mid', 0),
                    'take_profit_trailing': trend.get('take_profit_trailing', 0),
                    'take_profit_plan': trend.get('take_profit_plan', ''),
                    'resonance_count': trend.get('resonance_count', 0),
                    'resonance_signals': trend.get('resonance_signals', []),
                    'resonance_bonus': trend.get('resonance_bonus', 0),
                    'risk_reward_ratio': trend.get('risk_reward_ratio', 0),
                    'risk_reward_verdict': trend.get('risk_reward_verdict', ''),
                    'volatility_20d': trend.get('volatility_20d', 0),
                    'max_drawdown_60d': trend.get('max_drawdown_60d', 0),
                }
                dashboard['quant_extras'] = quant_extras

                # å†³ç­–ç±»å‹
                advice = result.operation_advice
                if 'ä¹°' in advice or 'åŠ ä»“' in advice:
                    result.decision_type = 'buy'
                elif 'å–' in advice or 'å‡ä»“' in advice:
                    result.decision_type = 'sell'
                else:
                    result.decision_type = 'hold'

            # æ ‡æ³¨åˆ†ææ—¶é—´æˆ³ï¼ˆç›˜ä¸­å¤šæ¬¡åˆ†ææ—¶å¯åŒºåˆ†ï¼‰
            result.analysis_time = datetime.now().strftime('%H:%M')
            self._log(f"[åˆ†æå®Œæˆ] {stock_name}: å»ºè®®-{result.operation_advice}, è¯„åˆ†-{result.sentiment_score} (æ—¶é—´={result.analysis_time})")
            
            try:
                # æ¯åªè‚¡ç¥¨ç”¨ç‹¬ç«‹çš„ query_idï¼ˆbatch_id + codeï¼‰ï¼Œç¡®ä¿ WebUI å†å²è®°å½•èƒ½æ­£ç¡®å®šä½
                per_stock_query_id = f"{self.query_id}_{code}" if self.query_id else None
                self.storage.save_analysis_history(result=result, query_id=per_stock_query_id, report_type=report_type.value if hasattr(report_type, 'value') else str(report_type), news_content=search_content, context_snapshot=context if self.save_context_snapshot else None)
            except Exception as e:
                logger.error(f"ä¿å­˜åˆ†æå†å²å¤±è´¥: {e}")
            
            if single_stock_notify and self.notifier.is_available():
                try:
                    report = self.notifier.generate_single_stock_report(result)
                    self.notifier.send(report)
                except Exception as e:
                    logger.warning(f"[{code}] æ¨é€å¤±è´¥: {e}")
            return result
        except Exception as e:
            logger.exception(f"[{code}] å¤„ç†è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            return None

    def _send_notifications(self, results: List[AnalysisResult]):
        logger.info("æ­£åœ¨ç”Ÿæˆæ±‡æ€»æ—¥æŠ¥...")
        try:
            daily_report = self.notifier.generate_dashboard_report(results)
            self.notifier.send(daily_report)
            self.notifier.save_report_to_file(daily_report)
            # åŒæ—¶ä¿å­˜ä¸€ä»½ .txt åˆ°æœ¬åœ°ï¼Œä¸æ”¹å˜ PushPlus ç­‰æ¨é€é€»è¾‘
            from pathlib import Path
            reports_dir = Path(__file__).resolve().parents[2] / "reports"
            reports_dir.mkdir(parents=True, exist_ok=True)
            txt_name = f"report_{time.strftime('%Y%m%d')}.txt"
            txt_path = reports_dir / txt_name
            with open(txt_path, "w", encoding="utf-8") as f:
                f.write(daily_report)
            logger.info(f"æ—¥æŠ¥å·²ä¿å­˜ä¸º txt: {txt_path}")
        except Exception as e:
            logger.error(f"æ±‡æ€»æ¨é€å¤±è´¥: {e}")

    def _check_portfolio_risk(self, results: List[AnalysisResult]) -> List[str]:
        """
        ç»„åˆé£æ§æ£€æŸ¥ï¼šæ¿å—é›†ä¸­åº¦ + æ–¹å‘ä¸€è‡´æ€§ + æ€»ä»“ä½ä¸Šé™
        è¿”å›é£æ§å‘Šè­¦åˆ—è¡¨ï¼ˆç©ºåˆ—è¡¨=æ— å‘Šè­¦ï¼‰
        """
        warnings = []
        if len(results) < 2:
            return warnings

        # 1. æ¿å—é›†ä¸­åº¦æ£€æŸ¥
        sector_map = {}  # sector_name -> [stock_names]
        for r in results:
            # ä» context snapshot æˆ– dashboard ä¸­æå–æ¿å—ä¿¡æ¯
            sector = None
            if r.dashboard and isinstance(r.dashboard, dict):
                sector = r.dashboard.get('sector_name')
            if not sector:
                # å°è¯•ä» market_snapshot è·å–
                snap = r.market_snapshot or {}
                sector = snap.get('sector_name')
            if sector:
                sector_map.setdefault(sector, []).append(r.name or r.code)

        for sector, stocks in sector_map.items():
            if len(stocks) >= 2:
                ratio = len(stocks) / len(results) * 100
                if ratio >= 50:
                    warnings.append(
                        f"âš ï¸ æ¿å—é›†ä¸­é£é™©: {sector}æ¿å—å æ¯”{ratio:.0f}% ({', '.join(stocks)})ï¼Œ"
                        f"å»ºè®®åˆ†æ•£è‡³ä¸åŒè¡Œä¸šï¼Œé¿å…æ¿å—æ€§ç³»ç»Ÿé£é™©"
                    )

        # 2. æ–¹å‘ä¸€è‡´æ€§æ£€æŸ¥ï¼ˆå…¨éƒ¨åŒå‘çœ‹å¤š/çœ‹ç©ºçš„é£é™©ï¼‰
        buy_count = sum(1 for r in results if r.decision_type == 'buy')
        sell_count = sum(1 for r in results if r.decision_type == 'sell')
        total = len(results)

        if buy_count == total and total >= 3:
            warnings.append(
                f"âš ï¸ å…¨ä»“çœ‹å¤šé£é™©: å…¨éƒ¨{total}åªè‚¡ç¥¨å‡å»ºè®®ä¹°å…¥ï¼Œ"
                f"éœ€è­¦æƒ•ç³»ç»Ÿæ€§é£é™©ï¼ˆå¤§ç›˜å›è°ƒæ—¶å¯èƒ½å…¨çº¿äºæŸï¼‰"
            )
        elif sell_count == total and total >= 3:
            warnings.append(
                f"ğŸ’¡ å…¨ä»“çœ‹ç©ºä¿¡å·: å…¨éƒ¨{total}åªè‚¡ç¥¨å‡å»ºè®®å–å‡º/è§‚æœ›ï¼Œ"
                f"å¸‚åœºå¯èƒ½å¤„äºå¼±åŠ¿ï¼Œå»ºè®®é™ä½æ•´ä½“ä»“ä½"
            )

        # 3. æ€»ä»“ä½ä¸Šé™æ£€æŸ¥
        total_position = 0
        for r in results:
            # ä» dashboard ä¸­è·å–é‡åŒ–å»ºè®®ä»“ä½
            trend = getattr(r, 'market_snapshot', {}) or {}
            pos = 0
            if r.dashboard and isinstance(r.dashboard, dict):
                core = r.dashboard.get('core_conclusion', {})
                pos_advice = core.get('position_advice', {})
                pos_str = pos_advice.get('no_position', '')
                if 'ä»“ä½' in str(pos_str):
                    try:
                        import re
                        m = re.search(r'(\d+)%', str(pos_str))
                        if m:
                            pos = int(m.group(1))
                    except Exception:
                        pass
            total_position += pos

        if total_position > 80:
            warnings.append(
                f"âš ï¸ æ€»ä»“ä½è¿‡é«˜: å»ºè®®æ€»ä»“ä½{total_position}%è¶…è¿‡80%ä¸Šé™ï¼Œ"
                f"è¯·é™ä½éƒ¨åˆ†ä¸ªè‚¡ä»“ä½æˆ–å‡å°‘æŒè‚¡æ•°é‡"
            )

        # 4. é«˜ç›¸å…³æ€§æ£€æŸ¥ï¼ˆåŒæ¶¨è·Œå¹… > ç›¸å…³é˜ˆå€¼çš„è‚¡ç¥¨ï¼‰
        scores = [(r.name or r.code, r.sentiment_score) for r in results]
        high_score = [name for name, s in scores if s >= 70]
        low_score = [name for name, s in scores if s <= 30]

        if len(high_score) >= 3:
            warnings.append(
                f"ğŸ“Š å¤šè‚¡åŒæ—¶é«˜åˆ†: {', '.join(high_score)} è¯„åˆ†å‡â‰¥70ï¼Œ"
                f"æ£€æŸ¥æ˜¯å¦å±äºåŒä¸€æ¿å—/æ¦‚å¿µï¼Œé¿å…é›†ä¸­è¸©é›·"
            )

        return warnings

    def run(self, stock_codes: Optional[List[str]] = None, dry_run: bool = False, send_notification: bool = True) -> List[AnalysisResult]:
        """
        ä¸»æ‰§è¡Œå…¥å£ (ç”± main.py è°ƒç”¨)
        """
        start_time = time.time()
        if stock_codes is None:
            self.config.refresh_stock_list()
            stock_codes = self.config.stock_list
        if not stock_codes:
            logger.error("æœªé…ç½®è‡ªé€‰è‚¡åˆ—è¡¨")
            return []
        
        total_stocks = len(stock_codes)
        logger.info(f"===== å¯åŠ¨åˆ†æä»»åŠ¡: å…± {total_stocks} åªè‚¡ç¥¨ =====")

        # === é˜¶æ®µä¸€ï¼šä¸²è¡Œè·å–æ•°æ® ===
        logger.info("ğŸ¢ é˜¶æ®µä¸€ï¼šä¸²è¡Œè·å–æ•°æ® (é˜²å°æ§ & é¢„åŠ è½½)...")
        valid_stocks = [] 
        
        for i, code in enumerate(stock_codes):
            try:
                success, msg, df, quote = self.fetch_and_save_stock_data(code)
                
                # å°è¯•é¢„å–ç­¹ç æ•°æ®ï¼ˆé¿å¼€äº¤æ˜“é«˜å³°ï¼‰
                try:
                    import datetime
                    now = datetime.datetime.now()
                    # ç®€å•åˆ¤æ–­éäº¤æ˜“æ—¶é—´æ‰å¤§é‡é¢„å–
                    is_trading = ((now.hour == 9 and now.minute >= 15) or (9 < now.hour < 15))
                    if not is_trading:
                        if hasattr(self.fetcher_manager, 'get_chip_distribution'):
                            self.fetcher_manager.get_chip_distribution(code)
                except Exception:
                    pass 

                if success:
                    valid_stocks.append(code)
                    # ç¼“å­˜é˜¶æ®µä¸€ç»“æœï¼Œé˜¶æ®µäºŒå¤ç”¨é¿å…é‡å¤å–æ•°/æ‹¼æ¥
                    if df is not None and quote is not None:
                        self._prefetch_cache[code] = {"df": df, "quote": quote}
                    logger.info(f"[{i+1}/{total_stocks}] âœ… {code} æ•°æ®å°±ç»ª")
                    # ä¸²è¡Œé˜¶æ®µä¹Ÿç¨å¾®ä¼‘æ¯ä¸€ä¸‹ï¼Œé˜²æ­¢æ•°æ®æºå°IPï¼ˆå¿«é€Ÿæ¨¡å¼ç¼©çŸ­ï¼‰
                    if not dry_run:
                        time.sleep(0.2 if getattr(self.config, 'fast_mode', False) else 0.5)
                else:
                    logger.warning(f"[{i+1}/{total_stocks}] âŒ {code} æ•°æ®å¤±è´¥: {msg}")
                
            except Exception as e:
                logger.error(f"[{code}] æ•°æ®é¢„å–å¼‚å¸¸: {e}")

        # === é˜¶æ®µ1.5ï¼šä¿å­˜ä»Šæ—¥æŒ‡æ•°æ•°æ®ï¼ˆä¾› Beta è®¡ç®—ï¼‰ ===
        if self._market_monitor:
            try:
                snap = self._market_monitor.get_market_snapshot()
                if snap.get('success'):
                    for idx in snap.get('indices', []):
                        name = idx.get('name', '')
                        close_val = float(idx.get('close', 0))
                        pct = float(idx.get('change_pct', 0))
                        if name and close_val > 0:
                            self.storage.save_index_daily(name, close_val, pct)
            except Exception as e:
                logger.debug(f"ä¿å­˜æŒ‡æ•°æ—¥çº¿è·³è¿‡: {e}")

        # === é˜¶æ®µäºŒï¼šå¹¶å‘åˆ†æ ===
        # é¢„å–å®æ—¶è¡Œæƒ…ï¼ˆæ‰¹é‡é¢„çƒ­ï¼Œå¯é€‰ï¼‰
        if valid_stocks and hasattr(self.fetcher_manager, 'prefetch_realtime_quotes'):
            try:
                self.fetcher_manager.prefetch_realtime_quotes(valid_stocks)
            except Exception as e:
                logger.debug(f"prefetch_realtime_quotes è·³è¿‡: {e}")
        workers = self.max_workers if self.max_workers is not None else 1
        logger.info(f"ğŸ° é˜¶æ®µäºŒï¼šå¼€å¯ {workers} çº¿ç¨‹è¿›è¡Œ AI å¹¶å‘åˆ†æï¼ˆå¤šçº¿ç¨‹æ—¶æ—¥å¿—ä¼šäº¤é”™ï¼Œè‹¥éœ€é¡ºåºè¾“å‡ºè¯·ä½¿ç”¨ --workers 1ï¼‰...")
        single_stock_notify = getattr(self.config, 'single_stock_notify', False)
        report_type = ReportType.FULL if getattr(self.config, 'report_type', 'simple') == 'full' else ReportType.SIMPLE
        results: List[AnalysisResult] = []
        
        if not valid_stocks:
            logger.error("æ²¡æœ‰è·å–åˆ°ä»»ä½•æœ‰æ•ˆæ•°æ®ï¼Œç»ˆæ­¢åˆ†æ")
            return []

        # é˜¶æ®µäºŒï¼šå¤§ç›˜å¿«ç…§åªå–ä¸€æ¬¡ï¼ˆæ›´å¿«ã€æ›´ä¸€è‡´ï¼‰ï¼Œä¼ å…¥æ¯åªè‚¡ç¥¨
        market_overview_once: Optional[str] = None
        if self._market_monitor:
            try:
                snapshot = self._market_monitor.get_market_snapshot()
                if snapshot.get("success"):
                    vol = snapshot.get('total_volume', 'N/A')
                    indices = snapshot.get('indices', [])
                    idx_str = " / ".join([f"{i['name']} {i['change_pct']}%" for i in indices])
                    market_overview_once = f"ä»Šæ—¥ä¸¤å¸‚æˆäº¤é¢: {vol}äº¿ã€‚æŒ‡æ•°è¡¨ç°: {idx_str}ã€‚"
                    if is_market_intraday():
                        market_overview_once += "ï¼ˆä»¥ä¸Šä¸º**ç›˜ä¸­æ•°æ®**ï¼Œéæ”¶ç›˜ï¼›æˆäº¤é¢ä¸æ¶¨è·Œå¹…å‡ä¸ºæˆªè‡³å½“å‰ã€‚ï¼‰"
                    logger.info(f"ğŸ“Š [é˜¶æ®µäºŒ] å¤§ç›˜å¿«ç…§å·²è·å–ï¼ˆå…¨å±€å¤ç”¨ï¼‰: æˆäº¤é¢{vol}äº¿ | {idx_str}")
            except Exception as e:
                logger.warning(f"ğŸ“Š [é˜¶æ®µäºŒ] è·å–å¤§ç›˜å¿«ç…§å¤±è´¥(é™çº§ä¸ºé€è‚¡/ä¸æ³¨å…¥): {e}")

        with ThreadPoolExecutor(max_workers=workers) as executor:
            future_to_code = {
                executor.submit(
                    self.process_single_stock, 
                    code, 
                    skip_analysis=dry_run, 
                    single_stock_notify=single_stock_notify and send_notification, 
                    report_type=report_type, 
                    skip_data_fetch=True,
                    market_overview_override=market_overview_once
                ): code for code in valid_stocks
            }
            
            for future in as_completed(future_to_code):
                code = future_to_code[future]
                try:
                    res = future.result()
                    if res: results.append(res)
                except Exception as e:
                    logger.error(f"[{code}] AI åˆ†æä»»åŠ¡å¤±è´¥: {e}")
        
        logger.info(f"===== åˆ†æå®Œæˆï¼Œæ€»è€—æ—¶ {time.time() - start_time:.2f}s =====")

        # === é˜¶æ®µä¸‰ï¼šç»„åˆé£æ§æ£€æŸ¥ ===
        if len(results) >= 2:
            try:
                risk_warnings = self._check_portfolio_risk(results)
                if risk_warnings:
                    logger.warning("âš ï¸ ã€ç»„åˆé£æ§å‘Šè­¦ã€‘")
                    for w in risk_warnings:
                        logger.warning(f"  {w}")
                    # å°†é£æ§å‘Šè­¦æ³¨å…¥æ¯åªè‚¡ç¥¨çš„ risk_warning å­—æ®µ
                    warning_text = "\n".join(risk_warnings)
                    for r in results:
                        existing = r.risk_warning or ""
                        r.risk_warning = f"{existing}\nã€ç»„åˆé£æ§ã€‘{warning_text}".strip()
            except Exception as e:
                logger.debug(f"ç»„åˆé£æ§æ£€æŸ¥è·³è¿‡: {e}")

        # æ±‡æ€»æ¨é€ (å¦‚æœæ²¡å¼€å•è‚¡æ¨é€)
        if results and send_notification and not dry_run and not single_stock_notify:
            self._send_notifications(results)
            
        return results