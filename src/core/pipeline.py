# -*- coding: utf-8 -*-
import logging
import time
import random
import os
from typing import List, Dict, Optional, Any
from concurrent.futures import ThreadPoolExecutor, as_completed

# === å¯¼å…¥æ•°æ®æ¨¡å— (ä¿æŒå¥å£®æ€§) ===
try:
    from data_provider import DataFetcherManager
except ImportError:
    try:
        from data_provider.base import DataFetcherManager
    except ImportError:
        # å°è¯•ä»Ž src å¯¼å…¥
        from src.data_provider.base import DataFetcherManager

# å°è¯•å¯¼å…¥ F10 æ•°æ®èŽ·å–å™¨
try:
    from data_provider.fundamental_fetcher import get_fundamental_data
except ImportError:
    def get_fundamental_data(code): return {}

# å°è¯•å¯¼å…¥ å¤§ç›˜ç›‘æŽ§ (Market Monitor)
try:
    from data_provider.market_monitor import market_monitor
except ImportError:
    market_monitor = None

# === å†…éƒ¨æ¨¡å—å¯¼å…¥ ===
from src.stock_analyzer import StockTrendAnalyzer
from src.analyzer import GeminiAnalyzer, AnalysisResult
from src.notification import NotificationService
from src.storage import DatabaseManager  
from src.search_service import SearchService
from src.enums import ReportType

logger = logging.getLogger(__name__)

class StockAnalysisPipeline:
    """
    è‚¡ç¥¨åˆ†æžæµæ°´çº¿ (æœ€ç»ˆå®Œæ•´ä¿®å¤ç‰ˆ)
    é€‚é… main.py çš„ config ä¼ å‚è°ƒç”¨æ–¹å¼ï¼ŒåŒ…å«ä¸¤é˜¶æ®µæ‰§è¡Œå’Œé˜²å°å·é€»è¾‘
    """
    def __init__(self, config, max_workers=3, query_id=None, query_source="cli", save_context_snapshot=True, source_message=None, **kwargs):
        """
        åˆå§‹åŒ– - ä¸¥æ ¼é€‚é… main.py çš„è°ƒç”¨æ–¹å¼
        """
        self.config = config
        self.query_id = query_id
        self.query_source = query_source
        self.save_context_snapshot = save_context_snapshot
        self.source_message = source_message
        
        # === 1. é»˜è®¤é¡ºåºæ‰§è¡Œï¼ˆworkers=1ï¼‰ï¼Œé¿å…å¤šçº¿ç¨‹æ—¥å¿—äº¤é”™ ===
        if max_workers is None:
            max_workers = 1
            
        # === 2. åˆå§‹åŒ–å„ä¸ªæœåŠ¡ç»„ä»¶ ===
        self.fetcher_manager = DataFetcherManager()
        self.trend_analyzer = StockTrendAnalyzer()
        
        # åˆå§‹åŒ– LLM (ç›´æŽ¥ä»Ž config è¯»å– key)
        self.analyzer = GeminiAnalyzer(api_key=config.gemini_api_key)
        
        # åˆå§‹åŒ– é€šçŸ¥æœåŠ¡
        self.notifier = NotificationService(source_message=source_message)
        
        # åˆå§‹åŒ– æ•°æ®åº“
        self.storage = DatabaseManager() 
        
        # === 3. åˆå§‹åŒ–æœç´¢æœåŠ¡ & æ™ºèƒ½æµæŽ§ ===
        self.search_service = None
        has_search_key = False
        
        # æ£€æŸ¥æ˜¯å¦é…ç½®äº†ä»»ä½•ä¸€ç§æœç´¢ Key
        if (config.bocha_api_keys or config.tavily_api_keys or 
            config.serpapi_keys or os.getenv("PERPLEXITY_API_KEY")):
            
            self.search_service = SearchService(
                bocha_keys=config.bocha_api_keys,
                tavily_keys=config.tavily_api_keys,
                serpapi_keys=config.serpapi_keys
            )
            has_search_key = True

        # å¦‚æžœå¯ç”¨äº†æœç´¢ï¼Œå¼ºåˆ¶é™åˆ¶å¹¶å‘æ•°ï¼Œé˜²æ­¢ 429 é”™è¯¯
        if has_search_key:
            self.max_workers = min(max_workers, 2)
            logger.info(f"ðŸ•µï¸  [æ·±åº¦æ¨¡å¼] æœç´¢æœåŠ¡å·²å¯ç”¨ï¼Œå¹¶å‘é™åˆ¶ä¸º: {self.max_workers}")
        else:
            self.max_workers = max_workers
            logger.info(f"ðŸš€ [æžé€Ÿæ¨¡å¼] çº¯æœ¬åœ°åˆ†æžï¼Œå¹¶å‘æ•°: {self.max_workers}")

    def fetch_and_save_stock_data(self, code: str) -> (bool, str):
        """èŽ·å–æ•°æ®è¾…åŠ©å‡½æ•°"""
        try:
            # 120å¤©æ•°æ®ç”¨äºŽè®¡ç®—è¶‹åŠ¿
            df = self.fetcher_manager.get_merged_data(code, days=120)
            if df is None or df.empty:
                return False, "èŽ·å–æ•°æ®ä¸ºç©º"
            quote = self.fetcher_manager.get_realtime_quote(code)
            if not quote:
                return False, "å®žæ—¶è¡Œæƒ…èŽ·å–å¤±è´¥"
            return True, "Success"
        except Exception as e:
            return False, str(e)

    def _prepare_stock_context(self, code: str) -> Optional[Dict[str, Any]]:
        """å‡†å¤‡ AI åˆ†æžæ‰€éœ€çš„ä¸Šä¸‹æ–‡æ•°æ®"""
        quote = self.fetcher_manager.get_realtime_quote(code)
        if not quote:
            logger.warning(f"[{code}] æ— æ³•èŽ·å–å®žæ—¶è¡Œæƒ…ï¼Œè·³è¿‡")
            return None
        stock_name = quote.name
        
        try:
            daily_df = self.fetcher_manager.get_merged_data(code, days=120)
        except Exception as e:
            logger.warning(f"[{code}] èŽ·å–åˆå¹¶æ•°æ®å¤±è´¥: {e}")
            daily_df = None

        tech_report = "æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡ŒæŠ€æœ¯åˆ†æž"
        if daily_df is not None and not daily_df.empty:
            try:
                trend_result = self.trend_analyzer.analyze(daily_df, code)
                if quote.price:
                    trend_result.current_price = quote.price
                tech_report = self.trend_analyzer.format_analysis(trend_result)
            except Exception as e:
                logger.error(f"[{code}] æŠ€æœ¯åˆ†æžç”Ÿæˆå¤±è´¥: {e}")

        # ç­¹ç æ•°æ®
        chip_data = {}
        if getattr(self.config, 'enable_chip_distribution', False):
            if hasattr(self.fetcher_manager, '_chip_cache') and code in self.fetcher_manager._chip_cache:
                chip_data = self.fetcher_manager._chip_cache[code].to_dict()
        
        # F10 åŸºæœ¬é¢æ•°æ®
        fundamental_data = {}
        try:
            fundamental_data = get_fundamental_data(code)
        except Exception as e:
            pass

        # åŽ†å²è®°å¿†
        history_summary = None
        try:
            history_summary = self.storage.get_last_analysis_summary(code)
        except Exception as e:
            pass

        context = {
            'code': code,
            'stock_name': stock_name,
            'price': quote.price,
            'realtime': quote.to_dict(),
            'chip': chip_data,
            'technical_analysis_report': tech_report,
            'fundamental': fundamental_data,
            'history_summary': history_summary
        }
        return context

    def process_single_stock(self, code: str, skip_analysis: bool = False, single_stock_notify: bool = False, report_type: ReportType = ReportType.SIMPLE, skip_data_fetch: bool = False) -> Optional[AnalysisResult]:
        """å¤„ç†å•åªè‚¡ç¥¨çš„æ ¸å¿ƒé€»è¾‘"""
        try:
            context = self._prepare_stock_context(code)
            if not context: return None
            stock_name = context['stock_name']
            
            if skip_analysis:
                logger.info(f"[{code}] Dry-run æ¨¡å¼ï¼Œè·³è¿‡ AI åˆ†æž")
                return AnalysisResult(code=code, name=stock_name, reasoning="Dry Run æµ‹è¯•", operation_advice="è§‚æœ›", sentiment_score=50, trend_prediction="æµ‹è¯•", success=True)

            # === 1. æœç´¢èˆ†æƒ… (å¢žåŠ éšæœºå»¶è¿Ÿé˜²å°å·) ===
            search_content = ""
            if self.search_service:
                # éšæœºä¼‘çœ  2.0 - 5.0 ç§’
                sleep_time = random.uniform(2.0, 5.0)
                time.sleep(sleep_time)
                
                logger.info(f"ðŸ”Ž [{stock_name}] æ­£åœ¨ä¾¦æŸ¥èˆ†æƒ… (å»¶è¿Ÿ {sleep_time:.1f}s)...")
                try:
                    # å…¼å®¹ä¸åŒæŽ¥å£è°ƒç”¨æ–¹å¼
                    if hasattr(self.search_service, 'search_stock_news'):
                        resp = self.search_service.search_stock_news(code, stock_name)
                    else:
                        query = f"{stock_name} ({code}) è¿‘æœŸé‡å¤§åˆ©å¥½åˆ©ç©ºæ¶ˆæ¯ æœºæž„è§‚ç‚¹ ç ”æŠ¥"
                        resp = self.search_service.search(query)
                        
                    if resp and getattr(resp, 'success', False): 
                        search_content = resp.to_context()
                except Exception as e:
                    logger.warning(f"[{stock_name}] æœç´¢æœåŠ¡å¼‚å¸¸: {e}")

            # === 2. èŽ·å–å¤§ç›˜çŽ¯å¢ƒ ===
            market_overview = None
            if market_monitor:
                try:
                    snapshot = market_monitor.get_market_snapshot()
                    if snapshot.get('success'):
                        vol = snapshot.get('total_volume', 'N/A')
                        indices = snapshot.get('indices', [])
                        # æ ¼å¼åŒ–: "ä¸Šè¯æŒ‡æ•° +1.2% / æ·±è¯æˆæŒ‡ -0.5%"
                        idx_str = " / ".join([f"{i['name']} {i['change_pct']}%" for i in indices])
                        market_overview = f"ä»Šæ—¥ä¸¤å¸‚æˆäº¤é¢: {vol}äº¿ã€‚æŒ‡æ•°è¡¨çŽ°: {idx_str}ã€‚"
                except Exception as e:
                    logger.warning(f"[{stock_name}] èŽ·å–å¤§ç›˜æ•°æ®å¾®ç‘•: {e}")

            logger.info(f"ðŸ¤– [{stock_name}] è°ƒç”¨ LLM è¿›è¡Œåˆ†æž...")
            
            # === 3. æ‰§è¡Œåˆ†æž ===
            result = self.analyzer.analyze(
                context=context, 
                news_context=search_content, 
                role="trader",
                market_overview=market_overview 
            )
            
            if not result: return None
            logger.info(f"\n[åˆ†æžå®Œæˆ] {stock_name}: å»ºè®®-{result.operation_advice}, è¯„åˆ†-{result.sentiment_score}")
            
            try:
                self.storage.save_analysis_history(result=result, query_id=self.query_id, report_type=report_type.value if hasattr(report_type, 'value') else str(report_type), news_content=search_content, context_snapshot=context if self.save_context_snapshot else None)
            except Exception as e:
                logger.error(f"ä¿å­˜åˆ†æžåŽ†å²å¤±è´¥: {e}")
            
            if single_stock_notify and self.notifier.is_available():
                try:
                    report = self.notifier.generate_single_stock_report(result)
                    self.notifier.send(report)
                except Exception as e:
                    logger.warning(f"[{code}] æŽ¨é€å¤±è´¥: {e}")
            return result
        except Exception as e:
            logger.exception(f"[{code}] å¤„ç†è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            return None

    def _send_notifications(self, results: List[AnalysisResult]):
        logger.info("æ­£åœ¨ç”Ÿæˆæ±‡æ€»æ—¥æŠ¥...")
        try:
            daily_report = self.notifier.generate_dashboard_report(results)
            self.notifier.send(daily_report)
            self.notifier.save_report_to_file(daily_report)
        except Exception as e:
            logger.error(f"æ±‡æ€»æŽ¨é€å¤±è´¥: {e}")

    def run(self, stock_codes: Optional[List[str]] = None, dry_run: bool = False, send_notification: bool = True) -> List[AnalysisResult]:
        """
        ä¸»æ‰§è¡Œå…¥å£ (ç”± main.py è°ƒç”¨)
        """
        start_time = time.time()
        if stock_codes is None:
            self.config.refresh_stock_list()
            stock_codes = self.config.stock_list
        if not stock_codes:
            logger.error("æœªé…ç½®è‡ªé€‰è‚¡åˆ—è¡¨")
            return []
        
        total_stocks = len(stock_codes)
        logger.info(f"===== å¯åŠ¨åˆ†æžä»»åŠ¡: å…± {total_stocks} åªè‚¡ç¥¨ =====")

        # === é˜¶æ®µä¸€ï¼šä¸²è¡ŒèŽ·å–æ•°æ® ===
        logger.info("ðŸ¢ é˜¶æ®µä¸€ï¼šä¸²è¡ŒèŽ·å–æ•°æ® (é˜²å°æŽ§ & é¢„åŠ è½½)...")
        valid_stocks = [] 
        
        for i, code in enumerate(stock_codes):
            try:
                success, msg = self.fetch_and_save_stock_data(code)
                
                # å°è¯•é¢„å–ç­¹ç æ•°æ®ï¼ˆé¿å¼€äº¤æ˜“é«˜å³°ï¼‰
                try:
                    import datetime
                    now = datetime.datetime.now()
                    # ç®€å•åˆ¤æ–­éžäº¤æ˜“æ—¶é—´æ‰å¤§é‡é¢„å–
                    is_trading = ((now.hour == 9 and now.minute >= 15) or (9 < now.hour < 15))
                    if not is_trading:
                        if hasattr(self.fetcher_manager, 'get_chip_distribution'):
                            self.fetcher_manager.get_chip_distribution(code)
                except Exception:
                    pass 

                if success:
                    valid_stocks.append(code)
                    logger.info(f"[{i+1}/{total_stocks}] âœ… {code} æ•°æ®å°±ç»ª")
                    # ä¸²è¡Œé˜¶æ®µä¹Ÿç¨å¾®ä¼‘æ¯ä¸€ä¸‹ï¼Œé˜²æ­¢æ•°æ®æºå°IP
                    if not dry_run:
                        time.sleep(0.5)
                else:
                    logger.warning(f"[{i+1}/{total_stocks}] âŒ {code} æ•°æ®å¤±è´¥: {msg}")
                
            except Exception as e:
                logger.error(f"[{code}] æ•°æ®é¢„å–å¼‚å¸¸: {e}")

        # === é˜¶æ®µäºŒï¼šå¹¶å‘åˆ†æž ===
        workers = self.max_workers if self.max_workers is not None else 1
        logger.info(f"ðŸ° é˜¶æ®µäºŒï¼šå¼€å¯ {workers} çº¿ç¨‹è¿›è¡Œ AI å¹¶å‘åˆ†æžï¼ˆå¤šçº¿ç¨‹æ—¶æ—¥å¿—ä¼šäº¤é”™ï¼Œè‹¥éœ€é¡ºåºè¾“å‡ºè¯·ä½¿ç”¨ --workers 1ï¼‰...")
        single_stock_notify = getattr(self.config, 'single_stock_notify', False)
        report_type = ReportType.FULL if getattr(self.config, 'report_type', 'simple') == 'full' else ReportType.SIMPLE
        results: List[AnalysisResult] = []
        
        if not valid_stocks:
            logger.error("æ²¡æœ‰èŽ·å–åˆ°ä»»ä½•æœ‰æ•ˆæ•°æ®ï¼Œç»ˆæ­¢åˆ†æž")
            return []

        with ThreadPoolExecutor(max_workers=workers) as executor:
            future_to_code = {
                executor.submit(
                    self.process_single_stock, 
                    code, 
                    skip_analysis=dry_run, 
                    single_stock_notify=single_stock_notify and send_notification, 
                    report_type=report_type, 
                    skip_data_fetch=True
                ): code for code in valid_stocks
            }
            
            for future in as_completed(future_to_code):
                code = future_to_code[future]
                try:
                    res = future.result()
                    if res: results.append(res)
                except Exception as e:
                    logger.error(f"[{code}] AI åˆ†æžä»»åŠ¡å¤±è´¥: {e}")
        
        logger.info(f"===== åˆ†æžå®Œæˆï¼Œæ€»è€—æ—¶ {time.time() - start_time:.2f}s =====")
        
        # æ±‡æ€»æŽ¨é€ (å¦‚æžœæ²¡å¼€å•è‚¡æŽ¨é€)
        if results and send_notification and not dry_run and not single_stock_notify:
            self._send_notifications(results)
            
        return results