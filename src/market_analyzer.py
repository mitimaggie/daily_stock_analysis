# src/market_analyzer.py
# -*- coding: utf-8 -*-
"""
===================================
å¤§ç›˜å¤ç›˜åˆ†ææ¨¡å— (å®è§‚ç­–ç•¥å¢å¼ºç‰ˆ + æ¿å—æ•°æ®)
===================================
"""

import logging
from dataclasses import dataclass, field
from datetime import datetime
from typing import Optional, Dict, Any, List

from src.config import get_config
from src.search_service import get_search_service
from src.analyzer import get_analyzer

# === æ ¸å¿ƒä¿®æ”¹ï¼šè·¯å¾„ä¿®æ­£ ===
try:
    from data_provider import DataFetcherManager
except ImportError:
    from data_provider.base import DataFetcherManager

logger = logging.getLogger(__name__)

try:
    from data_provider.market_monitor import market_monitor
except ImportError:
    market_monitor = None
    logger.warning("æ— æ³•å¯¼å…¥ data_provider.market_monitor")


@dataclass
class MarketIndex:
    """å¤§ç›˜æŒ‡æ•°æ•°æ®"""
    code: str = ""                   # æŒ‡æ•°ä»£ç 
    name: str = ""                   # æŒ‡æ•°åç§°
    current: float = 0.0             # å½“å‰ç‚¹ä½
    change: float = 0.0              # æ¶¨è·Œç‚¹æ•°
    change_pct: float = 0.0          # æ¶¨è·Œå¹…(%)
    open: float = 0.0                # å¼€ç›˜ç‚¹ä½
    high: float = 0.0                # æœ€é«˜ç‚¹ä½
    low: float = 0.0                 # æœ€ä½ç‚¹ä½
    prev_close: float = 0.0          # æ˜¨æ”¶ç‚¹ä½
    volume: float = 0.0              # æˆäº¤é‡(æ‰‹)
    amount: float = 0.0              # æˆäº¤é¢(å…ƒ)
    amplitude: float = 0.0           # æŒ¯å¹…(%)

    def to_dict(self) -> Dict[str, Any]:
        return {
            'code': self.code, 'name': self.name,
            'current': self.current, 'change': self.change,
            'change_pct': self.change_pct, 'open': self.open,
            'high': self.high, 'low': self.low,
            'volume': self.volume, 'amount': self.amount,
            'amplitude': self.amplitude,
        }


@dataclass
class MarketOverview:
    """å¸‚åœºæ¦‚è§ˆæ•°æ®ç»“æ„"""
    date: str
    indices: List[MarketIndex] = field(default_factory=list)   # ä¸»è¦æŒ‡æ•°
    up_count: int = 0                  # ä¸Šæ¶¨å®¶æ•°
    down_count: int = 0                # ä¸‹è·Œå®¶æ•°
    flat_count: int = 0                # å¹³ç›˜å®¶æ•°
    limit_up_count: int = 0            # æ¶¨åœå®¶æ•°
    limit_down_count: int = 0          # è·Œåœå®¶æ•°
    total_amount: float = 0.0          # ä¸¤å¸‚æˆäº¤é¢(äº¿)
    top_sectors: List[Dict] = field(default_factory=list)      # æ¶¨å¹…å‰5æ¿å—
    bottom_sectors: List[Dict] = field(default_factory=list)   # è·Œå¹…å‰5æ¿å—

    @property
    def indices_text(self) -> str:
        """å‘åå…¼å®¹ï¼šæ ¼å¼åŒ–ä¸ºæ—§å­—ç¬¦ä¸²"""
        parts = []
        for idx in self.indices:
            emoji = "ğŸ”º" if idx.change_pct > 0 else "ğŸ’š" if idx.change_pct < 0 else "â–"
            parts.append(f"{idx.name} {emoji} {idx.change_pct}%")
        return " / ".join(parts)
    
class MarketAnalyzer:
    """å¤§ç›˜å¤ç›˜åˆ†æå™¨"""
    
    def __init__(self, search_service=None, analyzer=None):
        self.config = get_config()
        self.search_service = search_service if search_service else get_search_service()
        self.analyzer = analyzer if analyzer else get_analyzer()
        self.data_manager = DataFetcherManager() 

    def run_daily_review(self) -> str:
        """æ‰§è¡Œæ¯æ—¥å¤§ç›˜å¤ç›˜æµç¨‹"""
        logger.info("========== å¼€å§‹å¤§ç›˜å¤ç›˜åˆ†æ (å®è§‚è§†è§’) ==========")
        overview = self.get_market_overview()
        news = self.search_market_news()
        report = self.generate_market_review(overview, news)
        logger.info("========== å¤§ç›˜å¤ç›˜åˆ†æå®Œæˆ ==========")
        return report

    def get_market_overview(self) -> MarketOverview:
        """è·å–å¸‚åœºæ¦‚è§ˆæ•°æ®"""
        today = datetime.now().strftime('%Y-%m-%d')
        overview = MarketOverview(date=today)
        
        # 1. è·å–æŒ‡æ•°å’Œæˆäº¤é¢ (ä» market_monitor)
        if market_monitor:
            try:
                data = market_monitor.get_market_snapshot()
                if data.get('success'):
                    overview.total_amount = data.get('total_volume', 0.0)
                    for idx_data in data.get('indices', []):
                        mi = MarketIndex(
                            name=idx_data.get('name', ''),
                            current=float(idx_data.get('close', 0)),
                            change_pct=float(idx_data.get('change_pct', 0)),
                        )
                        overview.indices.append(mi)
                    logger.info(f"[å¤§ç›˜] æŒ‡æ•°æ•°æ®è·å–å®Œæ¯•: {overview.indices_text}")
            except Exception as e:
                logger.warning(f"[å¤§ç›˜] Monitorè·å–æ•°æ®å¼‚å¸¸: {e}")

        # 2. è·å–æ¶¨è·Œç»Ÿè®¡ï¼ˆå¸‚åœºå¹¿åº¦ï¼‰
        self._get_market_statistics(overview)

        # 3. è·å–æ¿å—æ¶¨è·Œæ¦œï¼ˆå«é¢†æ¶¨+é¢†è·Œï¼‰
        self._get_sector_rankings(overview)
            
        return overview

    def _get_market_statistics(self, overview: MarketOverview) -> None:
        """è·å–æ¶¨è·Œå®¶æ•°ã€æ¶¨åœè·Œåœç­‰å¸‚åœºå¹¿åº¦æ•°æ®
        
        å¤ç”¨ akshare_fetcher çš„ _realtime_cacheï¼ˆ1200s TTLï¼‰ï¼Œé¿å…é‡å¤è¯·æ±‚ä¸œè´¢è¢«æ–­è¿ã€‚
        """
        try:
            # ä¼˜å…ˆå¤ç”¨ akshare_fetcher æ¨¡å—çº§ç¼“å­˜ï¼ˆstock_zh_a_spot_em å…¨é‡è¡¨ï¼‰
            from data_provider.akshare_fetcher import _realtime_cache
            import time as _time
            df = None
            if _realtime_cache['data'] is not None and _time.time() - _realtime_cache['timestamp'] < _realtime_cache['ttl']:
                df = _realtime_cache['data']
                logger.debug("[å¤§ç›˜] æ¶¨è·Œç»Ÿè®¡: å¤ç”¨ EM ç¼“å­˜")
            else:
                # ç¼“å­˜è¿‡æœŸæ‰é‡æ–°æ‹‰å–
                import akshare as ak
                _time.sleep(1)  # ç®€å•é™æµ
                df = ak.stock_zh_a_spot_em()
                if df is not None and not df.empty:
                    _realtime_cache['data'] = df
                    _realtime_cache['timestamp'] = _time.time()

            if df is not None and not df.empty:
                pct_col = 'æ¶¨è·Œå¹…'
                if pct_col in df.columns:
                    valid = df[pct_col].dropna()
                    overview.up_count = int((valid > 0).sum())
                    overview.down_count = int((valid < 0).sum())
                    overview.flat_count = int((valid == 0).sum())
                    overview.limit_up_count = int((valid >= 9.9).sum())
                    overview.limit_down_count = int((valid <= -9.9).sum())
                    logger.info(f"[å¤§ç›˜] æ¶¨è·Œç»Ÿè®¡: æ¶¨{overview.up_count} è·Œ{overview.down_count} æ¶¨åœ{overview.limit_up_count} è·Œåœ{overview.limit_down_count}")
        except Exception as e:
            logger.warning(f"[å¤§ç›˜] æ¶¨è·Œç»Ÿè®¡è·å–å¤±è´¥: {e}")

    def _get_sector_rankings(self, overview: MarketOverview) -> None:
        """è·å–æ¿å—æ¶¨è·Œæ’è¡Œï¼ˆé¢†æ¶¨ + é¢†è·Œï¼‰"""
        try:
            top_list, bottom_list = self.data_manager.get_sector_rankings(n=5)
            if top_list:
                overview.top_sectors = [{"name": item['name'], "change_pct": item['change_pct']} for item in top_list]
                logger.info(f"[å¤§ç›˜] é¢†æ¶¨æ¿å—: {[s['name'] for s in overview.top_sectors]}")
            if bottom_list:
                overview.bottom_sectors = [{"name": item['name'], "change_pct": item['change_pct']} for item in bottom_list]
                logger.info(f"[å¤§ç›˜] é¢†è·Œæ¿å—: {[s['name'] for s in overview.bottom_sectors]}")
        except Exception as e:
            logger.warning(f"[å¤§ç›˜] æ¿å—æ•°æ®è·å–å¤±è´¥: {e}")

    def search_market_news(self) -> List[Dict]:
        """æœç´¢å¸‚åœºå®è§‚æ–°é—»"""
        if not self.search_service:
            return []
        
        all_news = []
        keywords = [
            "ä»Šæ—¥Aè‚¡ èµšé’±æ•ˆåº” æ¶¨è·Œå®¶æ•°", 
            "åŒ—å‘èµ„é‡‘ æµå‘ å®è§‚è§£è¯»",       
            "å¤®è¡Œ è´§å¸æ”¿ç­– æœ€æ–°æ¶ˆæ¯",
            "äººæ°‘å¸æ±‡ç‡ Aè‚¡ å½±å“",
            "ä»Šæ—¥Aè‚¡ å¤ç›˜ æœºæ„è§‚ç‚¹"
        ]
        
        logger.info("[å¤§ç›˜] å¼€å§‹æœç´¢å®è§‚æƒ…æŠ¥...")
        for query in keywords:
            try:
                results = self.search_service.search_news(query)
                if results:
                    all_news.extend(results)
            except Exception as e:
                logger.error(f"[å¤§ç›˜] æœç´¢ '{query}' å¤±è´¥: {e}")
        
        return all_news

    def generate_market_review(self, overview: MarketOverview, news: List) -> str:
        """AI ç”Ÿæˆå®è§‚ç­–ç•¥æŠ¥å‘Š"""
        
        news_text = ""
        deduplicated_news = []
        seen_titles = set()
        
        for n in news:
            title = n.get('title', 'æ— æ ‡é¢˜')
            if title not in seen_titles:
                deduplicated_news.append(n)
                seen_titles.add(title)

        for i, n in enumerate(deduplicated_news[:15], 1): 
            title = n.get('title', 'æ— æ ‡é¢˜')
            content = n.get('content', n.get('snippet', ''))[:200]
            news_text += f"{i}. ã€{title}ã€‘\n   {content}\n"

        volume_desc = f"{overview.total_amount} äº¿å…ƒ" if overview.total_amount > 0 else "æ¥å£æ•°æ®ç¼ºå¤±"
        indices_desc = overview.indices_text if overview.indices_text else "æ¥å£æ•°æ®ç¼ºå¤±"
        top_sector_desc = ", ".join(f"{s['name']}({s['change_pct']}%)" for s in overview.top_sectors) if overview.top_sectors else "æ¥å£æ•°æ®ç¼ºå¤±"
        bottom_sector_desc = ", ".join(f"{s['name']}({s['change_pct']}%)" for s in overview.bottom_sectors) if overview.bottom_sectors else "æ¥å£æ•°æ®ç¼ºå¤±"

        # å¸‚åœºå¹¿åº¦
        breadth_desc = "æ¥å£æ•°æ®ç¼ºå¤±"
        if overview.up_count > 0 or overview.down_count > 0:
            breadth_desc = (
                f"ä¸Šæ¶¨{overview.up_count}å®¶ / ä¸‹è·Œ{overview.down_count}å®¶ / å¹³ç›˜{overview.flat_count}å®¶ | "
                f"æ¶¨åœ{overview.limit_up_count} / è·Œåœ{overview.limit_down_count}"
            )

        from src.core.pipeline import is_market_intraday
        now = datetime.now()
        time_context = "ã€ç›˜ä¸­è§£ç›˜ã€‘" if is_market_intraday() else "ã€æ”¶ç›˜ç­–ç•¥æ—¥æŠ¥ã€‘"

        prompt = f"""è¯·ä»¥ã€å®è§‚ç­–ç•¥å¸ˆã€‘çš„èº«ä»½ï¼Œæ’°å†™ä¸€ä»½{time_context}ã€‚

# 1. å¸‚åœºæ ¸å¿ƒæ•°æ®
- æ—¶é—´: {now.strftime('%H:%M')}
- æŒ‡æ•°è¡¨ç°: {indices_desc}
- ä¸¤å¸‚æˆäº¤: {volume_desc}
- **å¸‚åœºå¹¿åº¦**: {breadth_desc}
- **é¢†æ¶¨æ¿å—**: {top_sector_desc}
- **é¢†è·Œæ¿å—**: {bottom_sector_desc}

# 2. å®è§‚èˆ†æƒ…ä¸çº¿ç´¢
{news_text if news_text else "æš‚æ— æ–°é—»"}

---
# ä»»åŠ¡è¦æ±‚ (Markdown)
è¯·è¾“å‡ºä¸€ä»½å¯¹å†²åŸºé‡‘é£æ ¼çš„ç­–ç•¥æ—¥æŠ¥ï¼Œç›´å‡»ç—›ç‚¹ï¼š

## ğŸ“Š {overview.date} å¸‚åœºå…¨æ™¯
### 1. å¸‚åœºå®šè°ƒ (Market Sentiment)
(ç”¨ä¸€ä¸ªè¯å®šä¹‰ä»Šæ—¥å¸‚åœºï¼šå¦‚â€œç¼©é‡é˜´è·Œâ€ã€â€œæ”¾é‡é€¼ç©ºâ€ã€‚ç®€è¿°ç†ç”±)

### 2. èµ„é‡‘ä¸åšå¼ˆ (Flows & Game)
- **èµšé’±æ•ˆåº”**: (ç»“åˆæ¶¨è·Œå®¶æ•°ã€æ¶¨åœè·Œåœå®¶æ•°ä¸é¢†æ¶¨/é¢†è·Œæ¿å—åˆ†æ)
- **ä¸»åŠ›æ„å›¾**: (æœºæ„æ˜¯åœ¨æ´—ç›˜è¿˜æ˜¯å‡ºè´§ï¼Ÿ)

### 3. å®è§‚é©±åŠ¨ (Macro Drivers)
(åˆ†ææ±‡ç‡ã€æ”¿ç­–ã€ç¾è‚¡æ˜ å°„ç­‰å½±å“)

### 4. äº¤æ˜“ç­–ç•¥ (Actionable Advice)
- **ä»“ä½å»ºè®®**: (ä¾‹å¦‚ï¼šå»ºè®®åŠä»“é˜²å®ˆ / å»ºè®®ç§¯æè¿›æ”»)
- **æ–¹å‘æŒ‡å¼•**: (çœ‹å¥½å“ªä¸ªé£æ ¼ï¼Ÿ)
"""
        try:
            logger.info("[å¤§ç›˜] æ­£åœ¨ç”Ÿæˆå®è§‚ç­–ç•¥æŠ¥å‘Š...")
            report = self.analyzer.chat(prompt)
            return report
        except Exception as e:
            logger.error(f"[å¤§ç›˜] AI ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
            return f"ç”ŸæˆæŠ¥å‘Šå‡ºé”™: {str(e)}"

def get_market_analyzer():
    return MarketAnalyzer()